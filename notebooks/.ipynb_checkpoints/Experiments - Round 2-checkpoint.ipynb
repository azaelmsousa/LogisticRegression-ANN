{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments - Round 2\n",
    "## Multinomial Logistic Regression (Softmax Regression)\n",
    "This notebook performs experiments for the classification of garments using the Multinomial Logistic Regression. The Multinomial Logitic Regression uses the softmax function to compute a single model capable of multiclass classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils.dataset_helper' from '../utils/dataset_helper.py'>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import SGD\n",
    "\n",
    "from utils import dataset_helper\n",
    "from importlib import reload\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "reload(dataset_helper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test  = dataset_helper.load_fasion_mnist(scaling='default')\n",
    "normalization_comparison.append(stats.describe(X_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test  = dataset_helper.load_fasion_mnist(scaling='mean_std')\n",
    "normalization_comparison.append(stats.describe(X_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test  = dataset_helper.load_fasion_mnist(scaling='min_max')\n",
    "normalization_comparison.append(stats.describe(X_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nobs</th>\n",
       "      <th>minmax</th>\n",
       "      <th>mean</th>\n",
       "      <th>variance</th>\n",
       "      <th>skewness</th>\n",
       "      <th>kurtosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>784</td>\n",
       "      <td>(0.0, 1.0)</td>\n",
       "      <td>0.381388</td>\n",
       "      <td>0.159553</td>\n",
       "      <td>0.219186</td>\n",
       "      <td>-1.816807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>784</td>\n",
       "      <td>(-1.9222308239853982, 4.205628133086459)</td>\n",
       "      <td>0.323895</td>\n",
       "      <td>1.181219</td>\n",
       "      <td>0.584337</td>\n",
       "      <td>0.005424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>784</td>\n",
       "      <td>(0.0, 1.0)</td>\n",
       "      <td>0.381489</td>\n",
       "      <td>0.159539</td>\n",
       "      <td>0.218514</td>\n",
       "      <td>-1.816866</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   nobs                                    minmax      mean  variance  \\\n",
       "0   784                                (0.0, 1.0)  0.381388  0.159553   \n",
       "1   784  (-1.9222308239853982, 4.205628133086459)  0.323895  1.181219   \n",
       "2   784                                (0.0, 1.0)  0.381489  0.159539   \n",
       "\n",
       "   skewness  kurtosis  \n",
       "0  0.219186 -1.816807  \n",
       "1  0.584337  0.005424  \n",
       "2  0.218514 -1.816866  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(normalization_comparison)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000\n",
      "785\n",
      "Iteration: 0 Cost= 2.077265486475514\n",
      "Iteration: 1 Cost= 1.9190906427399763\n",
      "Iteration: 2 Cost= 1.7889911084487566\n",
      "Iteration: 3 Cost= 1.6811544118230226\n",
      "Iteration: 4 Cost= 1.590984180697094\n",
      "Iteration: 5 Cost= 1.5148578544083742\n",
      "Iteration: 6 Cost= 1.4499507624162182\n",
      "Iteration: 7 Cost= 1.3940754999923606\n",
      "Iteration: 8 Cost= 1.3455346684752725\n",
      "Iteration: 9 Cost= 1.3030051680895967\n",
      "Iteration: 10 Cost= 1.2654481365083645\n",
      "Iteration: 11 Cost= 1.2320412971220212\n",
      "Iteration: 12 Cost= 1.202128049307293\n",
      "Iteration: 13 Cost= 1.1751794705597398\n",
      "Iteration: 14 Cost= 1.1507657680745267\n",
      "Iteration: 15 Cost= 1.1285347782027575\n",
      "Iteration: 16 Cost= 1.1081956356467\n",
      "Iteration: 17 Cost= 1.089506289151974\n",
      "Iteration: 18 Cost= 1.0722638737696262\n",
      "Iteration: 19 Cost= 1.0562972290512964\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Classification\n",
      "[9 2 1 ... 3 1 7]\n",
      "\n",
      "--- Expected Output\n",
      "[9 2 1 ... 8 1 5]\n",
      "\n",
      "myAccuracy:  0.6737\n",
      "skAccuracy:  0.6737\n",
      "\n",
      "myPrecision:  0.7005362695989213\n",
      "skPrecision:  0.6737\n",
      "\n",
      "myRecall:  0.6737000000000001\n",
      "skRecall:  0.6737\n",
      "\n",
      "myF1Score:  0.6868561036691819\n",
      "skF1Score:  0.6737\n"
     ]
    }
   ],
   "source": [
    "from SGD.softmax_logistic import *\n",
    "\n",
    "theta,acc = softmax_logistic.BGD(X_train,y_train,0.1,20)\n",
    "\n",
    "predY = classify_softmax(theta,X_test)\n",
    "\n",
    "print(\"\\n--- Classification\")\n",
    "print(predY)\n",
    "print(\"\\n--- Expected Output\")\n",
    "print(y_test)\n",
    "\n",
    "acc = AccuracyScore(y_test,predY,mode='multi')\n",
    "sk_acc = metrics.accuracy_score(y_test,predY)\n",
    "pre = PrecisionScore(y_test,predY,mode='multi')\n",
    "sk_pre = metrics.precision_score(y_test,predY,average='micro')\n",
    "recall = RecallScore(y_test,predY,mode='multi')\n",
    "sk_recall = metrics.recall_score(y_test,predY,average='micro')\n",
    "f = FbScore(y_test,predY,1,mode='multi')\n",
    "sk_f = metrics.f1_score(y_test,predY,average='micro')\n",
    "\n",
    "print()\n",
    "print(\"myAccuracy: \", str(acc))\n",
    "print(\"skAccuracy: \", str(sk_acc))\n",
    "print()\n",
    "print(\"myPrecision: \",str(pre))\n",
    "print(\"skPrecision: \",str(sk_pre))\n",
    "print()\n",
    "print(\"myRecall: \",str(recall))\n",
    "print(\"skRecall: \",str(sk_recall))\n",
    "print()\n",
    "print(\"myF1Score: \",str(f))\n",
    "print(\"skF1Score: \",str(sk_f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stochastic Mini batch\n",
      "----------------------------\n",
      "Number of Iterations: 100\n",
      "Learning rate: 0.0001\n",
      "----------------------------\n",
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "==============================================\n",
      "Training for class 0\n",
      "==============================================\n",
      "Number of samples: 48000\n",
      "Number of parameters: 785\n",
      "It: 1 Batch: 0 Epoch 1 Error 0.39929167 Train Acc: 0.89929167 lr: 0.00010000 Val Acc: 0.90283333\n",
      "It: 10 Batch: 0 Epoch 10 Error 0.39116256 Train Acc: 0.89929167 lr: 0.00010000 Val Acc: 0.90283333\n",
      "It: 20 Batch: 0 Epoch 20 Error 0.38237089 Train Acc: 0.89929167 lr: 0.00010000 Val Acc: 0.90283333\n",
      "It: 30 Batch: 0 Epoch 30 Error 0.37383262 Train Acc: 0.89929167 lr: 0.00010000 Val Acc: 0.90283333\n",
      "It: 40 Batch: 0 Epoch 40 Error 0.36554655 Train Acc: 0.89929167 lr: 0.00010000 Val Acc: 0.90283333\n",
      "It: 50 Batch: 0 Epoch 50 Error 0.35751036 Train Acc: 0.89929167 lr: 0.00010000 Val Acc: 0.90283333\n",
      "It: 60 Batch: 0 Epoch 60 Error 0.34972074 Train Acc: 0.89929167 lr: 0.00010000 Val Acc: 0.90283333\n",
      "It: 70 Batch: 0 Epoch 70 Error 0.34217360 Train Acc: 0.89929167 lr: 0.00010000 Val Acc: 0.90283333\n",
      "It: 80 Batch: 0 Epoch 80 Error 0.33486418 Train Acc: 0.89929167 lr: 0.00010000 Val Acc: 0.90283333\n",
      "It: 90 Batch: 0 Epoch 90 Error 0.32778716 Train Acc: 0.89929167 lr: 0.00010000 Val Acc: 0.90283333\n",
      "It: 100 Batch: 0 Epoch 100 Error 0.32093681 Train Acc: 0.89929167 lr: 0.00010000 Val Acc: 0.90283333\n",
      "Finished \n",
      " Whole Set Train Acc: 0.89929167 Val Acc: 0.90283333\n",
      "==============================================\n",
      "==============================================\n",
      "Training for class 1\n",
      "==============================================\n",
      "Number of samples: 48000\n",
      "Number of parameters: 785\n",
      "It: 1 Batch: 0 Epoch 1 Error 0.40027083 Train Acc: 0.90027083 lr: 0.00010000 Val Acc: 0.89891667\n",
      "It: 10 Batch: 0 Epoch 10 Error 0.39158613 Train Acc: 0.90027083 lr: 0.00010000 Val Acc: 0.89891667\n",
      "It: 20 Batch: 0 Epoch 20 Error 0.38219572 Train Acc: 0.90027083 lr: 0.00010000 Val Acc: 0.89891667\n",
      "It: 30 Batch: 0 Epoch 30 Error 0.37307940 Train Acc: 0.90027083 lr: 0.00010000 Val Acc: 0.89891667\n",
      "It: 40 Batch: 0 Epoch 40 Error 0.36423680 Train Acc: 0.90027083 lr: 0.00010000 Val Acc: 0.89891667\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-95010147c6f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m theta = SGD_one_vs_all(lr, max_iter, X_train, y_train, batch_type='Full',                        \n\u001b[1;32m     21\u001b[0m                        \u001b[0mbatch_sz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_sz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprint_interval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m                        \u001b[0mX_val\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m                        )\n\u001b[1;32m     24\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Time Spent \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/notebooks/local/LogisticRegression-ANN/SGD/custom_SGD.py\u001b[0m in \u001b[0;36mSGD_one_vs_all\u001b[0;34m(lr, max_iter, X, y, lr_optimizer, power_t, t, batch_type, batch_sz, print_interval, X_val, y_val)\u001b[0m\n\u001b[1;32m    386\u001b[0m                        \u001b[0mprint_interval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m                        \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m                        cy_val)\n\u001b[0m\u001b[1;32m    389\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"==============================================\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/notebooks/local/LogisticRegression-ANN/SGD/custom_SGD.py\u001b[0m in \u001b[0;36mSGD\u001b[0;34m(lr, max_iter, X, y, lr_optimizer, power_t, t, batch_type, batch_sz, print_interval, X_val, y_val, multinomial)\u001b[0m\n\u001b[1;32m    315\u001b[0m             \u001b[0mtheta_temp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad_logit_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta_temp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultinomial_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmultinomial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0macc_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcustom_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "from SGD.custom_SGD import *\n",
    "reload(custom_SGD)\n",
    "X, y, _, _  = dataset_helper.load_fasion_mnist()\n",
    "    \n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "lr = .0001\n",
    "max_iter = 100\n",
    "batch_sz = 256\n",
    "print_interval = 10\n",
    "\n",
    "print(\"\")\n",
    "print(\"Stochastic Mini batch\")\n",
    "print(\"----------------------------\")\n",
    "print(\"Number of Iterations:\",max_iter)\n",
    "print(\"Learning rate:\",lr)\n",
    "print(\"----------------------------\")\n",
    "start = time.process_time()\n",
    "theta = SGD_one_vs_all(lr, max_iter, X_train, y_train, batch_type='Full',                        \n",
    "                       batch_sz=batch_sz, print_interval=print_interval, \n",
    "                       X_val=X_val, y_val = y_val,\n",
    "                       )\n",
    "print(\"Time Spent \", time.process_time() - start)\n",
    "y_pred = classify(theta, X_val, binary=False)\n",
    "evalute_multiclass(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stochastic Mini batch\n",
      "----------------------------\n",
      "Number of Iterations: 50\n",
      "Learning rate: 0.0001\n",
      "----------------------------\n",
      "[0 1 2 3 4 5 6 7 8 9]\n",
      "==============================================\n",
      "Training softmax model\n",
      "==============================================\n",
      "Number of samples: 48000\n",
      "Number of parameters: 785\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (12000,784) and (10,785) not aligned: 784 (dim 1) != 10 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-7e5b62389de0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m theta = SGD_softmax(lr, max_iter, X_train, y_train, batch_type='Full',\n\u001b[1;32m     14\u001b[0m                     \u001b[0mbatch_sz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_sz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprint_interval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     X_val=X_val, y_val = y_val)\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Time Spent \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassify_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/notebooks/local/LogisticRegression-ANN/SGD/custom_SGD.py\u001b[0m in \u001b[0;36mSGD_softmax\u001b[0;34m(lr, max_iter, X, y, lr_optimizer, power_t, t, batch_type, batch_sz, print_interval, X_val, y_val)\u001b[0m\n\u001b[1;32m    414\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mSGD_test_binary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/notebooks/local/LogisticRegression-ANN/SGD/custom_SGD.py\u001b[0m in \u001b[0;36mSGD\u001b[0;34m(lr, max_iter, X, y, lr_optimizer, power_t, t, batch_type, batch_sz, print_interval, X_val, y_val, multinomial)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mX_val\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m             \u001b[0my_pred_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m             \u001b[0macc_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcustom_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/notebooks/local/LogisticRegression-ANN/SGD/custom_SGD.py\u001b[0m in \u001b[0;36mclassify\u001b[0;34m(theta, X, th, binary, multinomial_)\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhypothesis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/notebooks/local/LogisticRegression-ANN/SGD/custom_SGD.py\u001b[0m in \u001b[0;36mhypothesis\u001b[0;34m(theta, X, stable)\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0mGiven\u001b[0m \u001b[0mTheta\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mX\u001b[0m \u001b[0mset\u001b[0m \u001b[0mit\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mlogistic\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mits\u001b[0m \u001b[0minstances\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \"\"\"\n\u001b[0;32m---> 99\u001b[0;31m     \u001b[0mdot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;31m# Regular Sigmoid Function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (12000,784) and (10,785) not aligned: 784 (dim 1) != 10 (dim 0)"
     ]
    }
   ],
   "source": [
    "from utils import dataset_helper\n",
    "lr = .0001\n",
    "max_iter = 50\n",
    "batch_sz = 1\n",
    "print_interval = 10\n",
    "\n",
    "print(\"\")\n",
    "print(\"Stochastic Mini batch\")\n",
    "print(\"----------------------------\")\n",
    "print(\"Number of Iterations:\", max_iter)\n",
    "print(\"Learning rate:\", lr)\n",
    "print(\"----------------------------\")\n",
    "\n",
    "y_val_enc = dataset_helper.one_hot_encode(y_val)\n",
    "y_train_enc = dataset_helper.one_hot_encode(y_train)\n",
    "\n",
    "start = time.process_time()\n",
    "theta = SGD_softmax(lr=lr, max_iter=max_iter, X_train=X_train, y_train=y_train, batch_type='Full',\n",
    "                    batch_sz=batch_sz, print_interval=print_interval, \n",
    "                    X_val=X_val, y_val = y_val)\n",
    "print(\"Time Spent \", time.process_time() - start)\n",
    "y_pred = classify_softmax(theta, X_val)\n",
    "evalute_multiclass(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
