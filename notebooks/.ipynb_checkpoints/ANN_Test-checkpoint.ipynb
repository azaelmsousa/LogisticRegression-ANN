{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append('../')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from NN import network, activation_functions, loss_functions\n",
    "from NN import ANN\n",
    "X = np.array([[1,2],[3,4]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Code running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layer  1\n",
      "[[0.73612102 0.86409973 0.94550467]\n",
      " [0.27731104 0.96830387 0.42965784]\n",
      " [0.55277393 0.99334975 0.67867461]] \n",
      "\n",
      "Output Layer \n",
      "[[0.68610231 0.62669577]\n",
      " [0.41204291 0.81429948]\n",
      " [0.7064625  0.02626637]\n",
      " [0.83362988 0.96219529]] \n",
      "\n",
      " Input size:  2\n",
      " Number of hidden layers:  1\n",
      " Number of perceptrons at each layer: \n",
      " HL 1: 3\n",
      " Number of classes: 2 \n",
      "\n",
      "Y\n",
      " [[2.52794771 2.28277363]\n",
      " [2.62286118 2.40448736]]\n",
      "\n",
      "a(Y)\n",
      " [[0.92607798 0.90744027]\n",
      " [0.93231847 0.91716885]]\n"
     ]
    }
   ],
   "source": [
    "# Random Init\n",
    "teste = ANN.ANN(\"sigmoid\")\n",
    "teste.initialize_random_weights(2, [3], 2)\n",
    "teste.show_weights()\n",
    "teste.show_setup()\n",
    "Y, aY = teste.foward_propagation(X)\n",
    "print(\"Y\\n\",Y)\n",
    "print(\"\\na(Y)\\n\",aY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing with the new Implementation by using the same weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.15 0.25]\n",
      " [0.2  0.3 ]]\n",
      "net [[0.3775 0.3925]]\n",
      "out [[0.59326999 0.59688438]]\n",
      "[[0.3775 0.3925]]\n",
      "[[0.59326999 0.59688438]]\n"
     ]
    }
   ],
   "source": [
    "from importlib import reload\n",
    "reload(network)\n",
    "I = np.array([[0.05, 0.10]])\n",
    "W = np.array([[0.15, 0.2], [0.25, 0.3]]).T\n",
    "h1 = network.Layer(2, 2, 'sigmoid', weights=W, bias=0.35, label=\"H1\")\n",
    "net, out =  h1.feed_forward(I)\n",
    "print(net)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.4  0.5 ]\n",
      " [0.45 0.55]]\n",
      "net [[1.10590597 1.2249214 ]]\n",
      "out [[0.75136507 0.77292847]]\n",
      "[[1.10590597 1.2249214 ]]\n",
      "[[0.75136507 0.77292847]]\n"
     ]
    }
   ],
   "source": [
    "from importlib import reload\n",
    "reload(network)\n",
    "I = np.array([[0.59326999, 0.59688438]])\n",
    "W = np.array([[0.4, 0.45], [0.50, 0.55]]).T\n",
    "o1 = network.Layer(2, 2, 'sigmoid', weights=W, bias=0.6, label=\"H1\")\n",
    "net, out =  o1.feed_forward(I)\n",
    "print(net)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Weights\n",
      "-------------------------------\n",
      "H1      (input=2, neurons=2, activation=sigmoid)\n",
      "[[0.15 0.25]\n",
      " [0.2  0.3 ]]\n",
      "H1      (input=2, neurons=2, activation=sigmoid)\n",
      "[[0.4  0.5 ]\n",
      " [0.45 0.55]]\n",
      "-------------------------------\n",
      "[[0.15 0.25]\n",
      " [0.2  0.3 ]]\n",
      "net [0.3775 0.3925]\n",
      "out [0.59326999 0.59688438]\n",
      "[[0.4  0.5 ]\n",
      " [0.45 0.55]]\n",
      "net [1.10590597 1.2249214 ]\n",
      "out [0.75136507 0.77292847]\n",
      "Y\n",
      " [[0.95636914 0.92270248]\n",
      " [0.96480669 0.9339985 ]]\n",
      "\n",
      "a(Y)\n",
      " [[0.502695]\n",
      " [1.508085]\n",
      " [3.01617 ]]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-107-89a7ee5b1ded>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\na(Y)\\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mY_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maY\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0maY_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from importlib import reload\n",
    "reload(network)\n",
    "model = network.NN(loss='mse')\n",
    "X = np.array([0.05, 0.10])\n",
    "Wh1 = np.array([[0.15, 0.2], [0.25, 0.3]]).T\n",
    "h1 = network.Layer(2, 2, 'sigmoid', weights=Wh1, bias=0.35, label=\"H1\")\n",
    "Wo1 = np.array([[0.4, 0.45], [0.50, 0.55]]).T\n",
    "o1 = network.Layer(2, 2, 'sigmoid', weights=Wo1, bias=0.6, label=\"H1\")\n",
    "model.add_layer(h1)\n",
    "model.add_layer(o1)\n",
    "model.show_weights()\n",
    "\n",
    "Y_, aY_ = model.feed_forward(X)\n",
    "\n",
    "print(\"Y\\n\",Y)\n",
    "print(\"\\na(Y)\\n\",aY)\n",
    "\n",
    "assert((Y - Y_).sum() == 0)\n",
    "assert((aY - aY_).sum() == 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-86-30ca6cd55b23>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-86-30ca6cd55b23>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    W = np.array([[0.15, 0.20], )\u001b[0m\n\u001b[0m                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "W = np.array([[0.15, 0.20], )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Weights\n",
      "-------------------------------\n",
      "H1      (input=2, neurons=2, activation=sigmoid)\n",
      "[[0.73612102 0.86409973 0.94550467]\n",
      " [0.27731104 0.96830387 0.42965784]\n",
      " [0.55277393 0.99334975 0.67867461]]\n",
      "out     (input=2, neurons=2, activation=sigmoid)\n",
      "[[0.68610231 0.62669577]\n",
      " [0.41204291 0.81429948]\n",
      " [0.7064625  0.02626637]\n",
      " [0.83362988 0.96219529]]\n",
      "-------------------------------\n"
     ]
    }
   ],
   "source": [
    "reload(network)\n",
    "model = network.NN(loss='mse')\n",
    "model.add_layer(network.Layer(2, 2, 'sigmoid', weights=teste.hidden_layers[0], label=\"H1\"))\n",
    "model.add_layer(network.Layer(2, 2, 'sigmoid', weights=teste.output_layer, label=\"out\"))\n",
    "model.show_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmax Sample and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Weights\n",
      "-------------------------------\n",
      "H1      (input=2, neurons=5, activation=sigmoid)\n",
      "[[0.08337952 0.04962746 0.54884556 0.61727976 0.08128913]\n",
      " [0.03133528 0.88056901 0.62274613 0.79323999 0.78845654]\n",
      " [0.83970096 0.94549912 0.09334806 0.74096189 0.73160972]]\n",
      "output  (input=5, neurons=2, activation=sigmoid)\n",
      "[[0.58778341 0.89637255]\n",
      " [0.62667996 0.91894214]\n",
      " [0.41729044 0.04236942]\n",
      " [0.2046778  0.02018469]\n",
      " [0.80679333 0.2180651 ]\n",
      " [0.70338664 0.58436175]]\n",
      "softmax (input=2, neurons=2, activation=softmax)\n",
      "[[1. 1.]\n",
      " [1. 1.]\n",
      " [1. 1.]]\n",
      "-------------------------------\n",
      "Y\n",
      " [[0.95636914 0.92270248]\n",
      " [0.96480669 0.9339985 ]]\n",
      "\n",
      "a(Y)\n",
      " [[0.50841587 0.49158413]\n",
      " [0.50770144 0.49229856]]\n"
     ]
    }
   ],
   "source": [
    "from importlib import reload\n",
    "reload(network)\n",
    "model = network.NN(loss='cross_entropy')\n",
    "model.add_layer(network.Layer(2, 5, 'sigmoid',  label=\"H1\"))\n",
    "model.add_layer(network.Layer(5, 2, 'sigmoid',  label=\"output\"))\n",
    "model.add_layer(network.Layer(2, 2, 'softmax',  label=\"softmax\"))\n",
    "model.show_weights()\n",
    "\n",
    "Y, aY = model.feed_forward(X)\n",
    "\n",
    "print(\"Y\\n\",Y)\n",
    "print(\"\\na(Y)\\n\",aY)\n",
    "assert(aY.sum() == aY.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the loss functions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Squared Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [ 2.7  8.1 16.2]\n",
      "1 [ 2.48  7.44 14.88]\n",
      "2 [ 2.282  6.846 13.692]\n",
      "3 [ 2.1038  6.3114 12.6228]\n",
      "4 [ 1.94342  5.83026 11.66052]\n",
      "5 [ 1.799078  5.397234 10.794468]\n",
      "6 [ 1.6691702  5.0075106 10.0150212]\n",
      "7 [1.55225318 4.65675954 9.31351908]\n",
      "8 [1.44702786 4.34108359 8.68216717]\n",
      "9 [1.35232508 4.05697523 8.11395045]\n",
      "10 [1.26709257 3.8012777  7.60255541]\n",
      "11 [1.19038331 3.57114993 7.14229987]\n",
      "12 [1.12134498 3.36403494 6.72806988]\n",
      "13 [1.05921048 3.17763145 6.35526289]\n",
      "14 [1.00328943 3.0098683  6.0197366 ]\n",
      "15 [0.95296049 2.85888147 5.71776294]\n",
      "16 [0.90766444 2.72299332 5.44598665]\n",
      "17 [0.866898   2.60069399 5.20138798]\n",
      "18 [0.8302082  2.49062459 4.98124919]\n",
      "19 [0.79718738 2.39156213 4.78312427]\n",
      "20 [0.76746864 2.30240592 4.60481184]\n",
      "21 [0.74072178 2.22216533 4.44433066]\n",
      "22 [0.7166496  2.1499488  4.29989759]\n",
      "23 [0.69498464 2.08495392 4.16990783]\n",
      "24 [0.67548617 2.02645852 4.05291705]\n",
      "25 [0.65793756 1.97381267 3.94762534]\n",
      "26 [0.6421438  1.9264314  3.85286281]\n",
      "27 [0.62792942 1.88378826 3.76757653]\n",
      "28 [0.61513648 1.84540944 3.69081888]\n",
      "29 [0.60362283 1.81086849 3.62173699]\n",
      "30 [0.59326055 1.77978164 3.55956329]\n",
      "31 [0.58393449 1.75180348 3.50360696]\n",
      "32 [0.57554104 1.72662313 3.45324626]\n",
      "33 [0.56798694 1.70396082 3.40792164]\n",
      "34 [0.56118825 1.68356474 3.36712947]\n",
      "35 [0.55506942 1.66520826 3.33041653]\n",
      "36 [0.54956248 1.64868744 3.29737487]\n",
      "37 [0.54460623 1.63381869 3.26763739]\n",
      "38 [0.54014561 1.62043682 3.24087365]\n",
      "39 [0.53613105 1.60839314 3.21678628]\n",
      "40 [0.53251794 1.59755383 3.19510765]\n",
      "41 [0.52926615 1.58779844 3.17559689]\n",
      "42 [0.52633953 1.5790186  3.1580372 ]\n",
      "43 [0.52370558 1.57111674 3.14223348]\n",
      "44 [0.52133502 1.56400507 3.12801013]\n",
      "45 [0.51920152 1.55760456 3.11520912]\n",
      "46 [0.51728137 1.5518441  3.10368821]\n",
      "47 [0.51555323 1.54665969 3.09331939]\n",
      "48 [0.51399791 1.54199372 3.08398745]\n",
      "49 [0.51259812 1.53779435 3.0755887 ]\n",
      "50 [0.51133831 1.53401492 3.06802983]\n",
      "51 [0.51020447 1.53061342 3.06122685]\n",
      "52 [0.50918403 1.52755208 3.05510416]\n",
      "53 [0.50826562 1.52479687 3.04959375]\n",
      "54 [0.50743906 1.52231719 3.04463437]\n",
      "55 [0.50669516 1.52008547 3.04017094]\n",
      "56 [0.50602564 1.51807692 3.03615384]\n",
      "57 [0.50542308 1.51626923 3.03253846]\n",
      "58 [0.50488077 1.51464231 3.02928461]\n",
      "59 [0.50439269 1.51317808 3.02635615]\n",
      "60 [0.50395342 1.51186027 3.02372054]\n",
      "61 [0.50355808 1.51067424 3.02134848]\n",
      "62 [0.50320227 1.50960682 3.01921363]\n",
      "63 [0.50288205 1.50864614 3.01729227]\n"
     ]
    }
   ],
   "source": [
    "reload(loss_functions)\n",
    "I = np.array([[1.5], [4.5], [9]])\n",
    "Y_  = np.array([[0.5], [1.5], [3]])\n",
    "W = np.array([[1.8]])\n",
    "lr = 0.01\n",
    "eps  = 0.01\n",
    "max_it = 100\n",
    "for i in range(max_it):\n",
    "    aY  = I * W\n",
    "    print(i, aY.flatten())\n",
    "    if np.absolute((Y_ - aY)).mean() < eps: \n",
    "        break\n",
    "    dC = loss_functions.mse_derivative(I, aY, Y_)\n",
    "    W = W - lr * dC\n",
    "\n",
    "assert(i > 0)\n",
    "assert(np.absolute((Y_ - aY)).mean() < eps)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Entropy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [ 2.7  8.1 16.2]\n",
      "1 [0.423 1.269 2.538]\n",
      "2 [0.502695 1.508085 3.01617 ]\n"
     ]
    }
   ],
   "source": [
    "reload(loss_functions)\n",
    "I = np.array([[1.5], [4.5], [9]])\n",
    "Y_  = np.array([[0.5], [1.5], [3]])\n",
    "W = np.array([[1.8]])\n",
    "\n",
    "for i in range(max_it):\n",
    "    aY  = I * W\n",
    "    print(i, aY.flatten())\n",
    "    if np.absolute((Y_ - aY)).mean() < eps: \n",
    "        break\n",
    "    dC = loss_functions.cross_entropy_derivative(I, aY, Y_)\n",
    "    W = W - lr * dC\n",
    "\n",
    "assert(i > 0)\n",
    "assert(np.absolute((Y_ - aY)).mean() < eps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sum of Squared Errors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [ 2.7  8.1 16.2]\n",
      "1 [0.423 1.269 2.538]\n",
      "2 [0.502695 1.508085 3.01617 ]\n"
     ]
    }
   ],
   "source": [
    "reload(loss_functions)\n",
    "I = np.array([[1.5], [4.5], [9]])\n",
    "Y_  = np.array([[0.5], [1.5], [3]])\n",
    "W = np.array([[1.8]])\n",
    "\n",
    "for i in range(max_it):\n",
    "    aY  = I * W\n",
    "    print(i, aY.flatten())\n",
    "    if np.absolute((Y_ - aY)).mean() < eps: \n",
    "        break\n",
    "    dC = loss_functions.smd_derivative(I, aY, Y_)\n",
    "    W = W - lr * dC\n",
    "assert(i > 0)\n",
    "assert(np.absolute((Y_ - aY)).mean() < eps)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
