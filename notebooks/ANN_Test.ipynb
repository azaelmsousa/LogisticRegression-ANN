{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append('../')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from NN import network, activation_functions, loss_functions\n",
    "from NN import ANN\n",
    "X = np.array([[1,2],[3,4]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Code running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layer  1\n",
      "[[0.27605372 0.1906593  0.30017076]\n",
      " [0.88279538 0.94562778 0.34077477]\n",
      " [0.64280095 0.65985464 0.67032014]] \n",
      "\n",
      "Output Layer \n",
      "[[0.59598795 0.87561001]\n",
      " [0.26656552 0.01072513]\n",
      " [0.45661502 0.13918876]\n",
      " [0.96476747 0.11160428]] \n",
      "\n",
      " Input size:  2\n",
      " Number of hidden layers:  1\n",
      " Number of perceptrons at each layer: \n",
      " HL 1: 3\n",
      " Number of classes: 2 \n",
      "\n",
      "Y\n",
      " [[2.10969738 1.1117549 ]\n",
      " [2.2639843  1.13460472]]\n",
      "\n",
      "a(Y)\n",
      " [[0.89184215 0.75245614]\n",
      " [0.90584999 0.75668768]]\n"
     ]
    }
   ],
   "source": [
    "# Random Init\n",
    "teste = ANN.ANN(\"sigmoid\")\n",
    "teste.initialize_random_weights(2, [3], 2)\n",
    "teste.show_weights()\n",
    "teste.show_setup()\n",
    "Y, aY = teste.foward_propagation(X)\n",
    "print(\"Y\\n\",Y)\n",
    "print(\"\\na(Y)\\n\",aY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing with the new Implementation by using the same weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H1 (1, 2) (2, 2)\n",
      "net [[0.3775 0.3925]]\n",
      "out [[0.59326999 0.59688438]]\n",
      "[[0.3775 0.3925]]\n",
      "[[0.59326999 0.59688438]]\n"
     ]
    }
   ],
   "source": [
    "from importlib import reload\n",
    "reload(network)\n",
    "I = np.array([[0.05, 0.10]])\n",
    "W = np.array([[0.15, 0.2], [0.25, 0.3]]).T\n",
    "h1 = network.Layer(2, 2, 'sigmoid', weights=W, bias=0.35, label=\"H1\")\n",
    "net, out =  h1.feed_forward(I)\n",
    "print(net)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H1 (1, 2) (2, 2)\n",
      "net [[1.10590597 1.2249214 ]]\n",
      "out [[0.75136507 0.77292847]]\n",
      "[[1.10590597 1.2249214 ]]\n",
      "[[0.75136507 0.77292847]]\n"
     ]
    }
   ],
   "source": [
    "from importlib import reload\n",
    "reload(network)\n",
    "I = np.array([[0.59326999, 0.59688438]])\n",
    "W = np.array([[0.4, 0.45], [0.50, 0.55]]).T\n",
    "o1 = network.Layer(2, 2, 'sigmoid', weights=W, bias=0.6, label=\"H1\")\n",
    "net, out =  o1.feed_forward(I)\n",
    "print(net)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Weights\n",
      "-------------------------------\n",
      "H1      (input=2, neurons=2, activation=sigmoid)\n",
      "[[0.15 0.25]\n",
      " [0.2  0.3 ]]\n",
      "H1      (input=2, neurons=2, activation=sigmoid)\n",
      "[[0.4  0.5 ]\n",
      " [0.45 0.55]]\n",
      "-------------------------------\n",
      "H1 (1, 2) (2, 2)\n",
      "net [[0.3775 0.3925]]\n",
      "out [[0.59326999 0.59688438]]\n",
      "H1 (1, 2) (2, 2)\n",
      "net [[1.10590597 1.2249214 ]]\n",
      "out [[0.75136507 0.77292847]]\n",
      "Y\n",
      " [[1.10590597 1.2249214 ]]\n",
      "\n",
      "a(Y)\n",
      " [[0.75136507 0.77292847]]\n"
     ]
    }
   ],
   "source": [
    "from importlib import reload\n",
    "reload(network)\n",
    "model = network.NN(loss='mse')\n",
    "X = np.array([[0.05, 0.10]])\n",
    "Wh1 = np.array([[0.15, 0.2], [0.25, 0.3]]).T\n",
    "h1 = network.Layer(2, 2, 'sigmoid', weights=Wh1, bias=0.35, label=\"H1\")\n",
    "Wo1 = np.array([[0.4, 0.45], [0.50, 0.55]]).T\n",
    "o1 = network.Layer(2, 2, 'sigmoid', weights=Wo1, bias=0.6, label=\"H1\")\n",
    "model.add_layer(h1)\n",
    "model.add_layer(o1)\n",
    "model.show_weights()\n",
    "\n",
    "Y_, aY_ = model.feed_forward(X)\n",
    "Y, aY = ([1.10590597, 1.2249214 ], [0.75136507, 0.77292847])\n",
    "print(\"Y\\n\",Y_)\n",
    "print(\"\\na(Y)\\n\",aY_)\n",
    "\n",
    "assert((Y - Y_).sum() < np.finfo(np.float32).eps)\n",
    "assert((aY - aY_).sum() < np.finfo(np.float32).eps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmax Sample and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Weights\n",
      "-------------------------------\n",
      "H1      (input=2, neurons=5, activation=sigmoid)\n",
      "[[0.15986824 0.78072515 0.15652473 0.39257536 0.409696  ]\n",
      " [0.93212521 0.50905525 0.61632734 0.81478519 0.29754673]]\n",
      "output  (input=5, neurons=2, activation=sigmoid)\n",
      "[[0.41174386 0.26122794]\n",
      " [0.15697582 0.3219758 ]\n",
      " [0.11543481 0.6027406 ]\n",
      " [0.20306723 0.40751777]\n",
      " [0.25848853 0.05099097]]\n",
      "-------------------------------\n",
      "H1 (1, 2) (2, 5)\n",
      "net [[1.10120593 1.08994178 1.06945897 1.10110729 1.05023947]]\n",
      "out [[0.75048599 0.74837076 0.74449401 0.75046752 0.74082088]]\n",
      "output (1, 5) (5, 2)\n",
      "net [[1.85631369 2.22934598]]\n",
      "out [[0.8648667  0.90285401]]\n",
      "Y\n",
      " [[1.85631369 2.22934598]]\n",
      "\n",
      "a(Y)\n",
      " [[0.8648667  0.90285401]]\n"
     ]
    }
   ],
   "source": [
    "from importlib import reload\n",
    "reload(network)\n",
    "model = network.NN(loss='cross_entropy')\n",
    "model.add_layer(network.Layer(2, 5, 'sigmoid',  label=\"H1\"))\n",
    "model.add_layer(network.Layer(5, 2, 'sigmoid',  label=\"output\"))\n",
    "model.show_weights()\n",
    "X = np.array([[0.05, 0.10]])\n",
    "Y, aY = model.feed_forward(X)\n",
    "\n",
    "print(\"Y\\n\",Y)\n",
    "print(\"\\na(Y)\\n\",aY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the loss functions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Squared Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [ 2.7  8.1 16.2]\n",
      "1 [ 2.48  7.44 14.88]\n",
      "2 [ 2.282  6.846 13.692]\n",
      "3 [ 2.1038  6.3114 12.6228]\n",
      "4 [ 1.94342  5.83026 11.66052]\n",
      "5 [ 1.799078  5.397234 10.794468]\n",
      "6 [ 1.6691702  5.0075106 10.0150212]\n",
      "7 [1.55225318 4.65675954 9.31351908]\n",
      "8 [1.44702786 4.34108359 8.68216717]\n",
      "9 [1.35232508 4.05697523 8.11395045]\n",
      "10 [1.26709257 3.8012777  7.60255541]\n",
      "11 [1.19038331 3.57114993 7.14229987]\n",
      "12 [1.12134498 3.36403494 6.72806988]\n",
      "13 [1.05921048 3.17763145 6.35526289]\n",
      "14 [1.00328943 3.0098683  6.0197366 ]\n",
      "15 [0.95296049 2.85888147 5.71776294]\n",
      "16 [0.90766444 2.72299332 5.44598665]\n",
      "17 [0.866898   2.60069399 5.20138798]\n",
      "18 [0.8302082  2.49062459 4.98124919]\n",
      "19 [0.79718738 2.39156213 4.78312427]\n",
      "20 [0.76746864 2.30240592 4.60481184]\n",
      "21 [0.74072178 2.22216533 4.44433066]\n",
      "22 [0.7166496  2.1499488  4.29989759]\n",
      "23 [0.69498464 2.08495392 4.16990783]\n",
      "24 [0.67548617 2.02645852 4.05291705]\n",
      "25 [0.65793756 1.97381267 3.94762534]\n",
      "26 [0.6421438  1.9264314  3.85286281]\n",
      "27 [0.62792942 1.88378826 3.76757653]\n",
      "28 [0.61513648 1.84540944 3.69081888]\n",
      "29 [0.60362283 1.81086849 3.62173699]\n",
      "30 [0.59326055 1.77978164 3.55956329]\n",
      "31 [0.58393449 1.75180348 3.50360696]\n",
      "32 [0.57554104 1.72662313 3.45324626]\n",
      "33 [0.56798694 1.70396082 3.40792164]\n",
      "34 [0.56118825 1.68356474 3.36712947]\n",
      "35 [0.55506942 1.66520826 3.33041653]\n",
      "36 [0.54956248 1.64868744 3.29737487]\n",
      "37 [0.54460623 1.63381869 3.26763739]\n",
      "38 [0.54014561 1.62043682 3.24087365]\n",
      "39 [0.53613105 1.60839314 3.21678628]\n",
      "40 [0.53251794 1.59755383 3.19510765]\n",
      "41 [0.52926615 1.58779844 3.17559689]\n",
      "42 [0.52633953 1.5790186  3.1580372 ]\n",
      "43 [0.52370558 1.57111674 3.14223348]\n",
      "44 [0.52133502 1.56400507 3.12801013]\n",
      "45 [0.51920152 1.55760456 3.11520912]\n",
      "46 [0.51728137 1.5518441  3.10368821]\n",
      "47 [0.51555323 1.54665969 3.09331939]\n",
      "48 [0.51399791 1.54199372 3.08398745]\n",
      "49 [0.51259812 1.53779435 3.0755887 ]\n",
      "50 [0.51133831 1.53401492 3.06802983]\n",
      "51 [0.51020447 1.53061342 3.06122685]\n",
      "52 [0.50918403 1.52755208 3.05510416]\n",
      "53 [0.50826562 1.52479687 3.04959375]\n",
      "54 [0.50743906 1.52231719 3.04463437]\n",
      "55 [0.50669516 1.52008547 3.04017094]\n",
      "56 [0.50602564 1.51807692 3.03615384]\n",
      "57 [0.50542308 1.51626923 3.03253846]\n",
      "58 [0.50488077 1.51464231 3.02928461]\n",
      "59 [0.50439269 1.51317808 3.02635615]\n",
      "60 [0.50395342 1.51186027 3.02372054]\n",
      "61 [0.50355808 1.51067424 3.02134848]\n",
      "62 [0.50320227 1.50960682 3.01921363]\n",
      "63 [0.50288205 1.50864614 3.01729227]\n"
     ]
    }
   ],
   "source": [
    "reload(loss_functions)\n",
    "I = np.array([[1.5], [4.5], [9]])\n",
    "Y_  = np.array([[0.5], [1.5], [3]])\n",
    "W = np.array([[1.8]])\n",
    "lr = 0.01\n",
    "eps  = 0.01\n",
    "max_it = 100\n",
    "for i in range(max_it):\n",
    "    aY  = I * W\n",
    "    print(i, aY.flatten())\n",
    "    if np.absolute((Y_ - aY)).mean() < eps: \n",
    "        break\n",
    "    dC = loss_functions.mse_derivative(I, aY, Y_)\n",
    "    W = W - lr * dC\n",
    "\n",
    "assert(i > 0)\n",
    "assert(np.absolute((Y_ - aY)).mean() < eps)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Entropy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [ 2.7  8.1 16.2]\n",
      "1 [0.423 1.269 2.538]\n",
      "2 [0.502695 1.508085 3.01617 ]\n"
     ]
    }
   ],
   "source": [
    "reload(loss_functions)\n",
    "I = np.array([[1.5], [4.5], [9]])\n",
    "Y_  = np.array([[0.5], [1.5], [3]])\n",
    "W = np.array([[1.8]])\n",
    "\n",
    "for i in range(max_it):\n",
    "    aY  = I * W\n",
    "    print(i, aY.flatten())\n",
    "    if np.absolute((Y_ - aY)).mean() < eps: \n",
    "        break\n",
    "    dC = loss_functions.cross_entropy_derivative(I, aY, Y_)\n",
    "    W = W - lr * dC\n",
    "\n",
    "assert(i > 0)\n",
    "assert(np.absolute((Y_ - aY)).mean() < eps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sum of Squared Errors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [ 2.7  8.1 16.2]\n",
      "1 [0.423 1.269 2.538]\n",
      "2 [0.502695 1.508085 3.01617 ]\n"
     ]
    }
   ],
   "source": [
    "reload(loss_functions)\n",
    "I = np.array([[1.5], [4.5], [9]])\n",
    "Y_  = np.array([[0.5], [1.5], [3]])\n",
    "W = np.array([[1.8]])\n",
    "\n",
    "for i in range(max_it):\n",
    "    aY  = I * W\n",
    "    print(i, aY.flatten())\n",
    "    if np.absolute((Y_ - aY)).mean() < eps: \n",
    "        break\n",
    "    dC = loss_functions.smd_derivative(I, aY, Y_)\n",
    "    W = W - lr * dC\n",
    "assert(i > 0)\n",
    "assert(np.absolute((Y_ - aY)).mean() < eps)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
