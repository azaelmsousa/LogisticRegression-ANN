{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append('../')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from NN import network, activation_functions, loss_functions\n",
    "from NN import ANN\n",
    "X = np.array([[1,2],[3,4]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Code running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layer  1\n",
      "[[0.94873394 0.11414162 0.55954911]\n",
      " [0.58339539 0.53380147 0.94712821]\n",
      " [0.64962293 0.17700522 0.44960808]] \n",
      "\n",
      "Output Layer \n",
      "[[0.89201452 0.8027576 ]\n",
      " [0.98750924 0.8081617 ]\n",
      " [0.52182774 0.93853488]\n",
      " [0.96373231 0.53303754]] \n",
      "\n",
      " Input size:  2\n",
      " Number of hidden layers:  1\n",
      " Number of perceptrons at each layer: \n",
      " HL 1: 3\n",
      " Number of classes: 2 \n",
      "\n",
      "Y\n",
      " [[3.09026194 2.74137004]\n",
      " [3.31240253 2.99915082]]\n",
      "\n",
      "a(Y)\n",
      " [[0.95648927 0.93942411]\n",
      " [0.96485185 0.95253575]]\n"
     ]
    }
   ],
   "source": [
    "# Random Init\n",
    "teste = ANN.ANN(\"sigmoid\")\n",
    "teste.initialize_random_weights(2, [3], 2)\n",
    "teste.show_weights()\n",
    "teste.show_setup()\n",
    "Y, aY = teste.foward_propagation(X)\n",
    "print(\"Y\\n\",Y)\n",
    "print(\"\\na(Y)\\n\",aY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing with the new Implementation by using the same weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.3775 0.3925]]\n",
      "[[0.59326999 0.59688438]]\n"
     ]
    }
   ],
   "source": [
    "from importlib import reload\n",
    "reload(network)\n",
    "I = np.array([[0.05, 0.10]])\n",
    "W = np.array([[0.15, 0.2], [0.25, 0.3]]).T\n",
    "h1 = network.Layer(2, 2, 'sigmoid', weights=W, bias=0.35, label=\"H1\")\n",
    "netH, outH =  h1.feed_forward(I)\n",
    "print(netH)\n",
    "print(outH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.10590597 1.2249214 ]]\n",
      "[[0.75136507 0.77292847]]\n"
     ]
    }
   ],
   "source": [
    "from importlib import reload\n",
    "reload(network)\n",
    "I = np.array([[0.59326999, 0.59688438]])\n",
    "W = np.array([[0.4, 0.45], [0.50, 0.55]]).T\n",
    "o1 = network.Layer(2, 2, 'sigmoid', weights=W, bias=0.6, label=\"H1\")\n",
    "netO, outO =  o1.feed_forward(I)\n",
    "print(netO)\n",
    "print(outO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y\n",
      " [1.10590597, 1.2249214]\n",
      "\n",
      "a(Y)\n",
      " [0.75136507, 0.77292847]\n"
     ]
    }
   ],
   "source": [
    "from importlib import reload\n",
    "reload(network)\n",
    "model = network.NN(loss='smd')\n",
    "X = np.array([[0.05, 0.10]])\n",
    "\n",
    "Wh = np.array([[0.15, 0.2], [0.25, 0.3]]).T\n",
    "h = network.Layer(2, 2, 'sigmoid', weights=Wh, bias=0.35, label=\"H1\")\n",
    "\n",
    "Wo = np.array([[0.4, 0.45], [0.50, 0.55]]).T\n",
    "o = network.Layer(2, 2, 'sigmoid', weights=Wo, bias=0.6, label=\"H1\")\n",
    "model.add_layer(h)\n",
    "model.add_layer(o)\n",
    "model.show_weights()\n",
    "\n",
    "Y, aY = model.feed_forward(X)\n",
    "Y_, aY_ = ([1.10590597, 1.2249214 ], [0.75136507, 0.77292847])\n",
    "print(\"Y\\n\",Y_)\n",
    "print(\"\\na(Y)\\n\",aY_)\n",
    "\n",
    "assert((Y - Y_).sum() < np.finfo(np.float32).eps)\n",
    "assert((aY - aY_).sum() < np.finfo(np.float32).eps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working on the back propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2983711087600027\n"
     ]
    }
   ],
   "source": [
    "from importlib import reload\n",
    "reload(network)\n",
    "model.show_weights()\n",
    "Y = np.array([0.01, 0.99])\n",
    "Etotal = loss_functions.smd(aY, Y)\n",
    "print(Etotal)\n",
    "assert((Etotal - 0.2983711) < np.finfo(np.float32).eps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Emulating the weights update for the layer O "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.74136507 -0.21707153]]\n",
      "dout [[0.1868156  0.17551005]]\n",
      "dnet [[0.59326999 0.59688438]]\n",
      "delta [[ 0.13849856 -0.03809824]]\n",
      "dw [[ 0.08216704 -0.02274024]]\n",
      "update [[0.35891648 0.51137012]\n",
      " [0.40891648 0.56137012]]\n"
     ]
    }
   ],
   "source": [
    "reload(loss_functions)\n",
    "reload(activation_functions)\n",
    "lr = 0.5\n",
    "#Done - Partial\n",
    "dEo_dw = loss_functions.smd_derivative_chain(outO, Y)\n",
    "print(dEo_dw)\n",
    "\n",
    "# Done\n",
    "dOuto_Dneto = activation_functions.sigmoid_derivative_chain(outO)\n",
    "print('dout',dOuto_Dneto)\n",
    "\n",
    "# Done - Self.input\n",
    "dNeto  = outH\n",
    "print('dnet',dNeto) \n",
    "# Done\n",
    "deltaO  = dEo_dw * dOuto_Dneto\n",
    "print('delta', deltaO)\n",
    "\n",
    "dWO = deltaO * outH\n",
    "print('dw', dWO)\n",
    "# Done\n",
    "updateO = Wo - lr * dWO\n",
    "print('update', updateO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.05539942 -0.01904912]\n",
      " [ 0.06232435 -0.02095403]]\n",
      "dETotal_dOh [0.03635031 0.04137032]\n",
      "dOuth_Dneth [[0.24130071 0.24061342]]\n",
      "deltaH [[0.00877135 0.00995425]]\n",
      "dWh [[0.00043857 0.00099543]]\n",
      "update [[0.14978072 0.24950229]\n",
      " [0.19978072 0.29950229]]\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Done - Partial\n",
    "dEo_dOh = deltaO * Wo\n",
    "dETotal_dOh = dEo_dOh.sum(axis=1)\n",
    "print (dEo_dOh)\n",
    "print('dETotal_dOh', dETotal_dOh)\n",
    "\n",
    "# Done\n",
    "dOuth_Dneth = activation_functions.sigmoid_derivative_chain(outH)\n",
    "print('dOuth_Dneth', dOuth_Dneth)\n",
    "\n",
    "\n",
    "# Done\n",
    "deltaH = dETotal_dOh * dOuth_Dneth \n",
    "print('deltaH', deltaH)\n",
    "\n",
    "# done\n",
    "# self.input\n",
    "dNeth_dw = X\n",
    "dWh = deltaH * dNeth_dw\n",
    "print('dWh', dWh)\n",
    "\n",
    "# Done\n",
    "updateH = Wh - lr * dWh\n",
    "print('update', updateH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 error 0.2983711087600027\n",
      "1000 error 0.0011202377365627065\n",
      "2000 error 0.00044785141631775586\n",
      "3000 error 0.00025349028036380844\n",
      "4000 error 0.00016571865888432704\n",
      "5000 error 0.00011734553835230822\n",
      "6000 error 8.7442721889668e-05\n",
      "7000 error 6.75166200528868e-05\n",
      "8000 error 5.351545683205839e-05\n",
      "9000 error 4.32812038815559e-05\n",
      "10000 error 3.556829373023961e-05\n",
      "11000 error 2.961232064457121e-05\n",
      "12000 error 2.4920877822775443e-05\n",
      "13000 error 2.1164068391319185e-05\n",
      "14000 error 1.8113574397803993e-05\n",
      "15000 error 1.5607002184429376e-05\n",
      "16000 error 1.3526123820153284e-05\n",
      "17000 error 1.1783116670472732e-05\n",
      "18000 error 1.0311590002491457e-05\n",
      "19000 error 9.060575063147334e-06\n",
      "20000 error 7.990404544484642e-06\n",
      "21000 error 7.06982827068485e-06\n",
      "22000 error 6.273956558913241e-06\n",
      "23000 error 5.5827692280249095e-06\n",
      "24000 error 4.980018389688318e-06\n",
      "25000 error 4.4524099926329095e-06\n",
      "26000 error 3.988985709203115e-06\n",
      "27000 error 3.5806508172542315e-06\n",
      "28000 error 3.2198098315234526e-06\n",
      "29000 error 2.9000825910317485e-06\n",
      "30000 error 2.6160810729356184e-06\n",
      "31000 error 2.363232500467144e-06\n",
      "32000 error 2.137638070648829e-06\n",
      "33000 error 1.935959325743895e-06\n",
      "34000 error 1.7553261514852517e-06\n",
      "35000 error 1.5932618224011568e-06\n",
      "36000 error 1.4476215793258673e-06\n",
      "37000 error 1.3165420201818315e-06\n",
      "38000 error 1.1983991853592908e-06\n",
      "39000 error 1.0917736752401948e-06\n",
      "40000 error 9.954214868709007e-07\n",
      "41000 error 9.082495263430995e-07\n",
      "42000 error 8.29294962815346e-07\n",
      "43000 error 7.577077537539029e-07\n",
      "44000 error 6.92735799676023e-07\n",
      "45000 error 6.337122884861457e-07\n",
      "46000 error 5.800448704572433e-07\n",
      "47000 error 5.31206369656754e-07\n",
      "48000 error 4.867267896258315e-07\n",
      "49000 error 4.461864131288249e-07\n",
      "[[0.01064666 0.98936729]]\n"
     ]
    }
   ],
   "source": [
    "reload(loss_functions)\n",
    "reload(activation_functions)\n",
    "reload(network)\n",
    "network.DEBUG = False\n",
    "\n",
    "X = np.array([[0.05, 0.10]], np.float64)\n",
    "\n",
    "Wh = np.array([[0.15, 0.2], [0.25, 0.3]], np.float64).T\n",
    "h = network.Layer(2, 2, 'sigmoid', weights=Wh, bias=0.35, label=\"H1\")\n",
    "\n",
    "Wo = np.array([[0.4, 0.45], [0.50, 0.55]], np.float64).T\n",
    "o = network.Layer(2, 2, 'sigmoid', weights=Wo, bias=0.6, label=\"H1\")\n",
    "Y = np.array([0.01, 0.99], np.float64)\n",
    "\n",
    "for i in range(50000):\n",
    "    netH, outH = h.feed_forward(X)\n",
    "#     print(netH, outH)\n",
    "    netO, outO = o.feed_forward(outH)\n",
    "#     print(netO, outO)\n",
    "    \n",
    "    Etotal = loss_functions.smd(outO, Y)\n",
    "    if (i % 1000) == 0:\n",
    "        print(i, 'error', Etotal)\n",
    "    \n",
    "    dEo_dw = loss_functions.smd_derivative_chain(outO, Y)\n",
    "    network.dprint(dEo_dw)\n",
    "    network.dprint (\"\")\n",
    "    network.dprint (\"==========================================\")\n",
    "    network.dprint (\"Back Propagate Layer O\")\n",
    "    network.dprint (\"==========================================\")\n",
    "    o.backpropagate(dETotal_dOut=dEo_dw)\n",
    "    network.dprint (\"==========================================\")\n",
    "    network.dprint (\"\")\n",
    "\n",
    "    network.dprint (\"==========================================\")\n",
    "    network.dprint (\"Back Propagate Layer H\")\n",
    "    network.dprint (\"==========================================\")\n",
    "    h.backpropagate(output_layer=o)\n",
    "    network.dprint (\"==========================================\")\n",
    "\n",
    "print (outO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmax Sample and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "reload(network)\n",
    "model = network.NN(loss='cross_entropy')\n",
    "model.add_layer(network.Layer(2, 5, 'sigmoid',  label=\"H1\"))\n",
    "model.add_layer(network.Layer(5, 2, 'sigmoid',  label=\"output\"))\n",
    "model.show_weights()\n",
    "X = np.array([[0.05, 0.10]])\n",
    "Y, aY = model.feed_forward(X)\n",
    "\n",
    "print(\"Y\\n\",Y)\n",
    "print(\"\\na(Y)\\n\",aY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the loss functions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Squared Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(loss_functions)\n",
    "I = np.array([[1.5], [4.5], [9]])\n",
    "Y_  = np.array([[0.5], [1.5], [3]])\n",
    "W = np.array([[1.8]])\n",
    "lr = 0.01\n",
    "eps  = 0.01\n",
    "max_it = 100\n",
    "for i in range(max_it):\n",
    "    aY  = I * W\n",
    "    print(i, aY.flatten())\n",
    "    if np.absolute((Y_ - aY)).mean() < eps: \n",
    "        break\n",
    "    dC = loss_functions.mse_derivative(I, aY, Y_)\n",
    "    W = W - lr * dC\n",
    "\n",
    "assert(i > 0)\n",
    "assert(np.absolute((Y_ - aY)).mean() < eps)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Entropy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(loss_functions)\n",
    "I = np.array([[1.5], [4.5], [9]])\n",
    "Y_  = np.array([[0.5], [1.5], [3]])\n",
    "W = np.array([[1.8]])\n",
    "\n",
    "for i in range(max_it):\n",
    "    aY  = I * W\n",
    "    print(i, aY.flatten())\n",
    "    if np.absolute((Y_ - aY)).mean() < eps: \n",
    "        break\n",
    "    dC = loss_functions.cross_entropy_derivative(I, aY, Y_)\n",
    "    W = W - lr * dC\n",
    "\n",
    "assert(i > 0)\n",
    "assert(np.absolute((Y_ - aY)).mean() < eps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sum of Squared Errors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(loss_functions)\n",
    "I = np.array([[1.5], [4.5], [9]])\n",
    "Y_  = np.array([[0.5], [1.5], [3]])\n",
    "W = np.array([[1.8]])\n",
    "\n",
    "for i in range(max_it):\n",
    "    aY  = I * W\n",
    "    print(i, aY.flatten())\n",
    "    if np.absolute((Y_ - aY)).mean() < eps: \n",
    "        break\n",
    "    dC = loss_functions.smd_derivative(I, aY, Y_)\n",
    "    W = W - lr * dC\n",
    "assert(i > 0)\n",
    "assert(np.absolute((Y_ - aY)).mean() < eps)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
