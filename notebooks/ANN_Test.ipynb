{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append('../')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from NN import network, activation_functions, loss_functions\n",
    "from NN import ANN\n",
    "X = np.array([[1,2],[3,4]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Code running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layer  1\n",
      "[[0.49910255 0.86853766 0.20175092]\n",
      " [0.13500897 0.05661088 0.88562919]\n",
      " [0.85720335 0.45729096 0.08389379]] \n",
      "\n",
      "Output Layer \n",
      "[[0.41656271 0.64751417]\n",
      " [0.13480829 0.22349019]\n",
      " [0.46602173 0.02845841]\n",
      " [0.81667544 0.20098056]] \n",
      "\n",
      " Input size:  2\n",
      " Number of hidden layers:  1\n",
      " Number of perceptrons at each layer: \n",
      " HL 1: 3\n",
      " Number of classes: 2 \n",
      "\n",
      "Y\n",
      " [[1.57728714 1.0324786 ]\n",
      " [1.77509366 1.0881012 ]]\n",
      "\n",
      "a(Y)\n",
      " [[0.82881997 0.73739614]\n",
      " [0.85508998 0.748024  ]]\n"
     ]
    }
   ],
   "source": [
    "# Random Init\n",
    "teste = ANN.ANN(\"sigmoid\")\n",
    "teste.initialize_random_weights(2, [3], 2)\n",
    "teste.show_weights()\n",
    "teste.show_setup()\n",
    "Y, aY = teste.foward_propagation(X)\n",
    "print(\"Y\\n\",Y)\n",
    "print(\"\\na(Y)\\n\",aY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing with the new Implementation by using the same weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.3775 0.3925]]\n",
      "[[0.59326999 0.59688438]]\n"
     ]
    }
   ],
   "source": [
    "from importlib import reload\n",
    "reload(network)\n",
    "I = np.array([[0.05, 0.10]])\n",
    "W = np.array([[0.15, 0.2], [0.25, 0.3]]).T\n",
    "h1 = network.Layer(2, 2, 'sigmoid', weights=W, bias=0.35, label=\"H1\")\n",
    "netH, outH =  h1.feed_forward(I)\n",
    "print(netH)\n",
    "print(outH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.10590597 1.2249214 ]]\n",
      "[[0.75136507 0.77292847]]\n"
     ]
    }
   ],
   "source": [
    "from importlib import reload\n",
    "reload(network)\n",
    "I = np.array([[0.59326999, 0.59688438]])\n",
    "W = np.array([[0.4, 0.45], [0.50, 0.55]]).T\n",
    "o1 = network.Layer(2, 2, 'sigmoid', weights=W, bias=0.6, label=\"H1\")\n",
    "netO, outO =  o1.feed_forward(I)\n",
    "print(netO)\n",
    "print(outO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y\n",
      " [1.10590597, 1.2249214]\n",
      "\n",
      "a(Y)\n",
      " [0.75136507, 0.77292847]\n"
     ]
    }
   ],
   "source": [
    "from importlib import reload\n",
    "reload(network)\n",
    "model = network.NN(loss='smd')\n",
    "X = np.array([[0.05, 0.10]])\n",
    "\n",
    "Wh = np.array([[0.15, 0.2], [0.25, 0.3]]).T\n",
    "h = network.Layer(2, 2, 'sigmoid', weights=Wh, bias=0.35, label=\"H1\")\n",
    "\n",
    "Wo = np.array([[0.4, 0.45], [0.50, 0.55]]).T\n",
    "o = network.Layer(2, 2, 'sigmoid', weights=Wo, bias=0.6, label=\"H1\")\n",
    "model.add_layer(h)\n",
    "model.add_layer(o)\n",
    "model.show_weights()\n",
    "\n",
    "Y, aY = model.feed_forward(X)\n",
    "Y_, aY_ = ([1.10590597, 1.2249214 ], [0.75136507, 0.77292847])\n",
    "print(\"Y\\n\",Y_)\n",
    "print(\"\\na(Y)\\n\",aY_)\n",
    "\n",
    "assert((Y - Y_).sum() < np.finfo(np.float32).eps)\n",
    "assert((aY - aY_).sum() < np.finfo(np.float32).eps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working on the back propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2983711087600027\n"
     ]
    }
   ],
   "source": [
    "from importlib import reload\n",
    "reload(network)\n",
    "model.show_weights()\n",
    "Y = np.array([0.01, 0.99])\n",
    "Etotal = loss_functions.smd(aY, Y)\n",
    "print(Etotal)\n",
    "assert((Etotal - 0.2983711) < np.finfo(np.float32).eps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Emulating the weights update for the layer O "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.74136507 -0.21707153]]\n",
      "dout [[0.1868156  0.17551005]]\n",
      "dnet [[0.59326999 0.59688438]]\n",
      "delta [[ 0.13849856 -0.03809824]]\n",
      "dw [[ 0.08216704 -0.02274024]]\n",
      "update [[0.35891648 0.51137012]\n",
      " [0.40891648 0.56137012]]\n"
     ]
    }
   ],
   "source": [
    "reload(loss_functions)\n",
    "reload(activation_functions)\n",
    "lr = 0.5\n",
    "#Done - Partial\n",
    "dEo_dw = loss_functions.smd_derivative_chain(outO, Y)\n",
    "print(dEo_dw)\n",
    "\n",
    "# Done\n",
    "dOuto_Dneto = activation_functions.sigmoid_derivative_chain(outO)\n",
    "print('dout',dOuto_Dneto)\n",
    "\n",
    "# Done - Self.input\n",
    "dNeto  = outH\n",
    "print('dnet',dNeto) \n",
    "# Done\n",
    "deltaO  = dEo_dw * dOuto_Dneto\n",
    "print('delta', deltaO)\n",
    "\n",
    "dWO = deltaO * outH\n",
    "print('dw', dWO)\n",
    "# Done\n",
    "updateO = Wo - lr * dWO\n",
    "print('update', updateO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.05539942 -0.01904912]\n",
      " [ 0.06232435 -0.02095403]]\n",
      "dETotal_dOh [0.03635031 0.04137032]\n",
      "dOuth_Dneth [[0.24130071 0.24061342]]\n",
      "deltaH [[0.00877135 0.00995425]]\n",
      "dWh [[0.00043857 0.00099543]]\n",
      "update [[0.14978072 0.24950229]\n",
      " [0.19978072 0.29950229]]\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Done - Partial\n",
    "dEo_dOh = deltaO * Wo\n",
    "dETotal_dOh = dEo_dOh.sum(axis=1)\n",
    "print (dEo_dOh)\n",
    "print('dETotal_dOh', dETotal_dOh)\n",
    "\n",
    "# Done\n",
    "dOuth_Dneth = activation_functions.sigmoid_derivative_chain(outH)\n",
    "print('dOuth_Dneth', dOuth_Dneth)\n",
    "\n",
    "\n",
    "# Done\n",
    "deltaH = dETotal_dOh * dOuth_Dneth \n",
    "print('deltaH', deltaH)\n",
    "\n",
    "# done\n",
    "# self.input\n",
    "dNeth_dw = X\n",
    "dWh = deltaH * dNeth_dw\n",
    "print('dWh', dWh)\n",
    "\n",
    "# Done\n",
    "updateH = Wh - lr * dWh\n",
    "print('update', updateH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8, 7, 6, 5, 4, 3, 2, 1, 0]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in range(8, -1, -1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layer by Layer testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 error 0.2983711087600027\n",
      "1000 error 0.0011202377365627065\n",
      "2000 error 0.00044785141631775586\n",
      "3000 error 0.00025349028036380844\n",
      "4000 error 0.00016571865888432704\n",
      "5000 error 0.00011734553835230822\n",
      "6000 error 8.7442721889668e-05\n",
      "7000 error 6.75166200528868e-05\n",
      "8000 error 5.351545683205839e-05\n",
      "9000 error 4.32812038815559e-05\n",
      "[[0.01600365 0.98407495]]\n"
     ]
    }
   ],
   "source": [
    "reload(loss_functions)\n",
    "reload(activation_functions)\n",
    "reload(network)\n",
    "network.DEBUG = False\n",
    "\n",
    "X = np.array([[0.05, 0.10]], np.float64)\n",
    "\n",
    "Wh = np.array([[0.15, 0.2], [0.25, 0.3]], np.float64).T\n",
    "h = network.Layer(2, 2, 'sigmoid', weights=Wh, bias=0.35, label=\"H1\")\n",
    "\n",
    "Wo = np.array([[0.4, 0.45], [0.50, 0.55]], np.float64).T\n",
    "o = network.Layer(2, 2, 'sigmoid', weights=Wo, bias=0.6, label=\"H1\")\n",
    "Y = np.array([0.01, 0.99], np.float64)\n",
    "\n",
    "for i in range(10000):\n",
    "    netH, outH = h.feed_forward(X)\n",
    "#     print(netH, outH)\n",
    "    netO, outO = o.feed_forward(outH)\n",
    "#     print(netO, outO)\n",
    "    \n",
    "    Etotal = loss_functions.smd(outO, Y)\n",
    "    if (i % 1000) == 0:\n",
    "        print(i, 'error', Etotal)\n",
    "    \n",
    "    dEo_dw = loss_functions.smd_derivative_chain(outO, Y)\n",
    "    network.dprint(dEo_dw)\n",
    "    network.dprint (\"\")\n",
    "    network.dprint (\"==========================================\")\n",
    "    network.dprint (\"Back Propagate Layer O\")\n",
    "    network.dprint (\"==========================================\")\n",
    "    o.backpropagate(dETotal_dOut=dEo_dw)\n",
    "    network.dprint (\"==========================================\")\n",
    "    network.dprint (\"\")\n",
    "\n",
    "    network.dprint (\"==========================================\")\n",
    "    network.dprint (\"Back Propagate Layer H\")\n",
    "    network.dprint (\"==========================================\")\n",
    "    h.backpropagate(output_layer=o)\n",
    "    network.dprint (\"==========================================\")\n",
    "\n",
    "print (outO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Model Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 0.008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It: 1 Batch: 1 Epoch 0 Error: 0.29837111 lr: 0.50000000 \n",
      "Finished \n",
      " It: 209 Batch: 1 Epoch 208 Train Loss: 0.00795372 lr: 0.50000000 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[-2.11785483,  2.31889592]]), array([[0.1073735 , 0.91042995]]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import dataset_helper\n",
    "reload(loss_functions)\n",
    "reload(activation_functions)\n",
    "reload(network)\n",
    "reload(dataset_helper)\n",
    "network.DEBUG = False\n",
    "\n",
    "X = np.array([[0.05, 0.10]], np.float64)\n",
    "Y = np.array([[0.01, 0.99]], np.float64)\n",
    "\n",
    "Wh = np.array([[0.15, 0.2], [0.25, 0.3]], np.float64).T\n",
    "h = network.Layer(2, 2, 'sigmoid', weights=Wh, bias=0.35, label=\"H1\")\n",
    "\n",
    "Wo = np.array([[0.4, 0.45], [0.50, 0.55]], np.float64).T\n",
    "o = network.Layer(2, 2, 'sigmoid', weights=Wo, bias=0.6, label=\"Output\")\n",
    "\n",
    "model = network.NN(loss='smd')\n",
    "model.add_layer(h)\n",
    "model.add_layer(o)\n",
    "model.show_weights()\n",
    "\n",
    "model.fit(X, Y, max_iter=50000, \n",
    "          lr=0.5, epsilon=eps, \n",
    "          print_interval=2000)\n",
    "model.feed_forward(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmax Sample and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It: 1 Batch: 1 Epoch 0 Error: 1.65052853 lr: 0.50000000 \n",
      "It: 2000 Batch: 1 Epoch 1999 Error: 0.13206266 lr: 0.50000000 \n",
      "It: 4000 Batch: 1 Epoch 3999 Error: 0.12137317 lr: 0.50000000 \n",
      "It: 6000 Batch: 1 Epoch 5999 Error: 0.11759200 lr: 0.50000000 \n",
      "It: 8000 Batch: 1 Epoch 7999 Error: 0.11570863 lr: 0.50000000 \n",
      "It: 10000 Batch: 1 Epoch 9999 Error: 0.11461245 lr: 0.50000000 \n",
      "It: 12000 Batch: 1 Epoch 11999 Error: 0.11391401 lr: 0.50000000 \n",
      "It: 14000 Batch: 1 Epoch 13999 Error: 0.11344174 lr: 0.50000000 \n",
      "It: 16000 Batch: 1 Epoch 15999 Error: 0.11310871 lr: 0.50000000 \n",
      "It: 18000 Batch: 1 Epoch 17999 Error: 0.11286639 lr: 0.50000000 \n",
      "It: 20000 Batch: 1 Epoch 19999 Error: 0.11268576 lr: 0.50000000 \n",
      "It: 22000 Batch: 1 Epoch 21999 Error: 0.11254852 lr: 0.50000000 \n",
      "It: 24000 Batch: 1 Epoch 23999 Error: 0.11244259 lr: 0.50000000 \n",
      "It: 26000 Batch: 1 Epoch 25999 Error: 0.11235979 lr: 0.50000000 \n",
      "It: 28000 Batch: 1 Epoch 27999 Error: 0.11229435 lr: 0.50000000 \n",
      "It: 30000 Batch: 1 Epoch 29999 Error: 0.11224217 lr: 0.50000000 \n",
      "It: 32000 Batch: 1 Epoch 31999 Error: 0.11220022 lr: 0.50000000 \n",
      "It: 34000 Batch: 1 Epoch 33999 Error: 0.11216628 lr: 0.50000000 \n",
      "It: 36000 Batch: 1 Epoch 35999 Error: 0.11213865 lr: 0.50000000 \n",
      "It: 38000 Batch: 1 Epoch 37999 Error: 0.11211604 lr: 0.50000000 \n",
      "It: 40000 Batch: 1 Epoch 39999 Error: 0.11209746 lr: 0.50000000 \n",
      "It: 42000 Batch: 1 Epoch 41999 Error: 0.11208213 lr: 0.50000000 \n",
      "It: 44000 Batch: 1 Epoch 43999 Error: 0.11206943 lr: 0.50000000 \n",
      "It: 46000 Batch: 1 Epoch 45999 Error: 0.11205888 lr: 0.50000000 \n",
      "It: 48000 Batch: 1 Epoch 47999 Error: 0.11205009 lr: 0.50000000 \n",
      "It: 50000 Batch: 1 Epoch 49999 Error: 0.11204274 lr: 0.50000000 \n",
      "Finished \n",
      " It: 50000 Batch: 1 Epoch 49999 Train Loss: 0.11204274 lr: 0.50000000 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[-4.53180808,  4.53313307]]), array([[0.01064663, 0.98936732]]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import dataset_helper\n",
    "reload(loss_functions)\n",
    "reload(activation_functions)\n",
    "reload(network)\n",
    "reload(dataset_helper)\n",
    "network.DEBUG = False\n",
    "\n",
    "X = np.array([[0.05, 0.10]], np.float64)\n",
    "Y = np.array([[0.01, 0.99]], np.float64)\n",
    "\n",
    "Wh = np.array([[0.15, 0.2], [0.25, 0.3]], np.float64).T\n",
    "h = network.Layer(2, 2, 'sigmoid', weights=Wh, bias=0.35, label=\"H1\")\n",
    "\n",
    "Wo = np.array([[0.4, 0.45], [0.50, 0.55]], np.float64).T\n",
    "o = network.Layer(2, 2, 'sigmoid', weights=Wo, bias=0.6, label=\"Output\")\n",
    "\n",
    "model = network.NN(loss='cross_entropy')\n",
    "model.add_layer(h)\n",
    "model.add_layer(o)\n",
    "model.show_weights()\n",
    "\n",
    "model.fit(X, Y, max_iter=50000, \n",
    "          lr=0.5, epsilon=eps, \n",
    "          print_interval=2000)\n",
    "model.feed_forward(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It: 1 Batch: 1 Epoch 0 Error: 0.29837111 lr: 0.50000000 \n",
      "Finished \n",
      " It: 104 Batch: 1 Epoch 103 Train Loss: 0.00799325 lr: 0.50000000 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[-2.11897627,  2.31855525]]), array([[0.10726606, 0.91040216]]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import dataset_helper\n",
    "reload(loss_functions)\n",
    "reload(activation_functions)\n",
    "reload(network)\n",
    "reload(dataset_helper)\n",
    "network.DEBUG = False\n",
    "\n",
    "X = np.array([[0.05, 0.10]], np.float64)\n",
    "Y = np.array([[0.01, 0.99]], np.float64)\n",
    "\n",
    "Wh = np.array([[0.15, 0.2], [0.25, 0.3]], np.float64).T\n",
    "h = network.Layer(2, 2, 'sigmoid', weights=Wh, bias=0.35, label=\"H1\")\n",
    "\n",
    "Wo = np.array([[0.4, 0.45], [0.50, 0.55]], np.float64).T\n",
    "o = network.Layer(2, 2, 'sigmoid', weights=Wo, bias=0.6, label=\"Output\")\n",
    "\n",
    "model = network.NN(loss='mse')\n",
    "model.add_layer(h)\n",
    "model.add_layer(o)\n",
    "model.show_weights()\n",
    "\n",
    "model.fit(X, Y, max_iter=50000, \n",
    "          lr=0.5, epsilon=eps, \n",
    "          print_interval=2000)\n",
    "model.feed_forward(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the loss functions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Squared Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [ 2.7  8.1 16.2]\n",
      "1 [ 2.48  7.44 14.88]\n",
      "2 [ 2.282  6.846 13.692]\n",
      "3 [ 2.1038  6.3114 12.6228]\n",
      "4 [ 1.94342  5.83026 11.66052]\n",
      "5 [ 1.799078  5.397234 10.794468]\n",
      "6 [ 1.6691702  5.0075106 10.0150212]\n",
      "7 [1.55225318 4.65675954 9.31351908]\n",
      "8 [1.44702786 4.34108359 8.68216717]\n",
      "9 [1.35232508 4.05697523 8.11395045]\n",
      "10 [1.26709257 3.8012777  7.60255541]\n",
      "11 [1.19038331 3.57114993 7.14229987]\n",
      "12 [1.12134498 3.36403494 6.72806988]\n",
      "13 [1.05921048 3.17763145 6.35526289]\n",
      "14 [1.00328943 3.0098683  6.0197366 ]\n",
      "15 [0.95296049 2.85888147 5.71776294]\n",
      "16 [0.90766444 2.72299332 5.44598665]\n",
      "17 [0.866898   2.60069399 5.20138798]\n",
      "18 [0.8302082  2.49062459 4.98124919]\n",
      "19 [0.79718738 2.39156213 4.78312427]\n",
      "20 [0.76746864 2.30240592 4.60481184]\n",
      "21 [0.74072178 2.22216533 4.44433066]\n",
      "22 [0.7166496  2.1499488  4.29989759]\n",
      "23 [0.69498464 2.08495392 4.16990783]\n",
      "24 [0.67548617 2.02645852 4.05291705]\n",
      "25 [0.65793756 1.97381267 3.94762534]\n",
      "26 [0.6421438  1.9264314  3.85286281]\n",
      "27 [0.62792942 1.88378826 3.76757653]\n",
      "28 [0.61513648 1.84540944 3.69081888]\n",
      "29 [0.60362283 1.81086849 3.62173699]\n",
      "30 [0.59326055 1.77978164 3.55956329]\n",
      "31 [0.58393449 1.75180348 3.50360696]\n",
      "32 [0.57554104 1.72662313 3.45324626]\n",
      "33 [0.56798694 1.70396082 3.40792164]\n",
      "34 [0.56118825 1.68356474 3.36712947]\n",
      "35 [0.55506942 1.66520826 3.33041653]\n",
      "36 [0.54956248 1.64868744 3.29737487]\n",
      "37 [0.54460623 1.63381869 3.26763739]\n",
      "38 [0.54014561 1.62043682 3.24087365]\n",
      "39 [0.53613105 1.60839314 3.21678628]\n",
      "40 [0.53251794 1.59755383 3.19510765]\n",
      "41 [0.52926615 1.58779844 3.17559689]\n",
      "42 [0.52633953 1.5790186  3.1580372 ]\n",
      "43 [0.52370558 1.57111674 3.14223348]\n",
      "44 [0.52133502 1.56400507 3.12801013]\n",
      "45 [0.51920152 1.55760456 3.11520912]\n",
      "46 [0.51728137 1.5518441  3.10368821]\n",
      "47 [0.51555323 1.54665969 3.09331939]\n",
      "48 [0.51399791 1.54199372 3.08398745]\n",
      "49 [0.51259812 1.53779435 3.0755887 ]\n",
      "50 [0.51133831 1.53401492 3.06802983]\n",
      "51 [0.51020447 1.53061342 3.06122685]\n",
      "52 [0.50918403 1.52755208 3.05510416]\n",
      "53 [0.50826562 1.52479687 3.04959375]\n",
      "54 [0.50743906 1.52231719 3.04463437]\n",
      "55 [0.50669516 1.52008547 3.04017094]\n",
      "56 [0.50602564 1.51807692 3.03615384]\n",
      "57 [0.50542308 1.51626923 3.03253846]\n",
      "58 [0.50488077 1.51464231 3.02928461]\n",
      "59 [0.50439269 1.51317808 3.02635615]\n",
      "60 [0.50395342 1.51186027 3.02372054]\n",
      "61 [0.50355808 1.51067424 3.02134848]\n",
      "62 [0.50320227 1.50960682 3.01921363]\n",
      "63 [0.50288205 1.50864614 3.01729227]\n"
     ]
    }
   ],
   "source": [
    "reload(loss_functions)\n",
    "I = np.array([[1.5], [4.5], [9]])\n",
    "Y_  = np.array([[0.5], [1.5], [3]])\n",
    "W = np.array([[1.8]])\n",
    "lr = 0.01\n",
    "eps  = 0.01\n",
    "max_it = 100\n",
    "for i in range(max_it):\n",
    "    aY  = I * W\n",
    "    print(i, aY.flatten())\n",
    "    if np.absolute((Y_ - aY)).mean() < eps: \n",
    "        break\n",
    "    dC = loss_functions.mse_derivative(I, aY, Y_)\n",
    "    W = W - lr * dC\n",
    "\n",
    "assert(i > 0)\n",
    "assert(np.absolute((Y_ - aY)).mean() < eps)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Entropy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [ 2.7  8.1 16.2]\n",
      "1 [0.423 1.269 2.538]\n",
      "2 [0.502695 1.508085 3.01617 ]\n"
     ]
    }
   ],
   "source": [
    "reload(loss_functions)\n",
    "I = np.array([[1.5], [4.5], [9]])\n",
    "Y_  = np.array([[0.5], [1.5], [3]])\n",
    "W = np.array([[1.8]])\n",
    "\n",
    "for i in range(max_it):\n",
    "    aY  = I * W\n",
    "    print(i, aY.flatten())\n",
    "    if np.absolute((Y_ - aY)).mean() < eps: \n",
    "        break\n",
    "    dC = loss_functions.cross_entropy_derivative(I, aY, Y_)\n",
    "    W = W - lr * dC\n",
    "\n",
    "assert(i > 0)\n",
    "assert(np.absolute((Y_ - aY)).mean() < eps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sum of Squared Errors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [ 2.7  8.1 16.2]\n",
      "1 [0.423 1.269 2.538]\n",
      "2 [0.502695 1.508085 3.01617 ]\n"
     ]
    }
   ],
   "source": [
    "reload(loss_functions)\n",
    "I = np.array([[1.5], [4.5], [9]])\n",
    "Y_  = np.array([[0.5], [1.5], [3]])\n",
    "W = np.array([[1.8]])\n",
    "\n",
    "for i in range(max_it):\n",
    "    aY  = I * W\n",
    "    print(i, aY.flatten())\n",
    "    if np.absolute((Y_ - aY)).mean() < eps: \n",
    "        break\n",
    "    dC = loss_functions.smd_derivative(I, aY, Y_)\n",
    "    W = W - lr * dC\n",
    "assert(i > 0)\n",
    "assert(np.absolute((Y_ - aY)).mean() < eps)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
