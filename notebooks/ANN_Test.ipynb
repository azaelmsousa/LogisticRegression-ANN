{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.local/lib/python3.5/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import sys \n",
    "sys.path.append('../')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from NN import network, activation_functions, loss_functions\n",
    "from NN import ANN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Run Checks\n",
    "To identify if there is no code broken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.3775 0.3925]]\n",
      "[[0.59326999 0.59688438]]\n"
     ]
    }
   ],
   "source": [
    "from importlib import reload\n",
    "reload(network)\n",
    "I = np.array([[0.05, 0.10]])\n",
    "W = np.array([[0.15, 0.2], [0.25, 0.3]]).T\n",
    "h1 = network.Layer(2, 2, 'sigmoid', weights=W, bias=0.35, label=\"H1\")\n",
    "netH, outH =  h1.feed_forward(I)\n",
    "print(netH)\n",
    "print(outH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.10590597 1.2249214 ]]\n",
      "[[0.75136507 0.77292847]]\n"
     ]
    }
   ],
   "source": [
    "from importlib import reload\n",
    "reload(network)\n",
    "I = np.array([[0.59326999, 0.59688438]])\n",
    "W = np.array([[0.4, 0.45], [0.50, 0.55]]).T\n",
    "o1 = network.Layer(2, 2, 'sigmoid', weights=W, bias=0.6, label=\"H1\")\n",
    "netO, outO =  o1.feed_forward(I)\n",
    "print(netO)\n",
    "print(outO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convergence Checkings\n",
    "Based on the sample given by the class teacher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y\n",
      " [1.10590597, 1.2249214]\n",
      "\n",
      "a(Y)\n",
      " [0.75136507, 0.77292847]\n"
     ]
    }
   ],
   "source": [
    "from importlib import reload\n",
    "reload(network)\n",
    "model = network.NN(loss='smd')\n",
    "X = np.array([[0.05, 0.10]])\n",
    "\n",
    "Wh = np.array([[0.15, 0.2], [0.25, 0.3]]).T\n",
    "h = network.Layer(2, 2, 'sigmoid', weights=Wh, bias=0.35, label=\"H1\")\n",
    "\n",
    "Wo = np.array([[0.4, 0.45], [0.50, 0.55]]).T\n",
    "o = network.Layer(2, 2, 'sigmoid', weights=Wo, bias=0.6, label=\"H1\")\n",
    "model.add_layer(h)\n",
    "model.add_layer(o)\n",
    "model.show_weights()\n",
    "\n",
    "Y, aY = model.feed_forward(X)\n",
    "Y_, aY_ = ([1.10590597, 1.2249214 ], [0.75136507, 0.77292847])\n",
    "print(\"Y\\n\",Y_)\n",
    "print(\"\\na(Y)\\n\",aY_)\n",
    "\n",
    "assert((Y - Y_).sum() < np.finfo(np.float32).eps)\n",
    "assert((aY - aY_).sum() < np.finfo(np.float32).eps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working on the back propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2983711087600027\n"
     ]
    }
   ],
   "source": [
    "from importlib import reload\n",
    "reload(network)\n",
    "model.show_weights()\n",
    "Y = np.array([0.01, 0.99])\n",
    "Etotal = loss_functions.smd(aY, Y)\n",
    "print(Etotal)\n",
    "assert((Etotal - 0.2983711) < np.finfo(np.float32).eps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Emulating the weights update for the layer O "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.74136507 -0.21707153]]\n",
      "dout [[0.1868156  0.17551005]]\n",
      "dnet [[0.59326999 0.59688438]]\n",
      "delta [[ 0.13849856 -0.03809824]]\n",
      "dw [[ 0.08216704 -0.02274024]]\n",
      "update [[0.35891648 0.51137012]\n",
      " [0.40891648 0.56137012]]\n"
     ]
    }
   ],
   "source": [
    "reload(loss_functions)\n",
    "reload(activation_functions)\n",
    "lr = 0.5\n",
    "#Done - Partial\n",
    "dEo_dw = loss_functions.smd_derivative_chain(outO, Y)\n",
    "print(dEo_dw)\n",
    "\n",
    "# Done\n",
    "dOuto_Dneto = activation_functions.sigmoid_derivative_chain(outO)\n",
    "print('dout',dOuto_Dneto)\n",
    "\n",
    "# Done - Self.input\n",
    "dNeto  = outH\n",
    "print('dnet',dNeto) \n",
    "# Done\n",
    "deltaO  = dEo_dw * dOuto_Dneto\n",
    "print('delta', deltaO)\n",
    "\n",
    "dWO = deltaO * outH\n",
    "print('dw', dWO)\n",
    "# Done\n",
    "updateO = Wo - lr * dWO\n",
    "print('update', updateO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.05539942 -0.01904912]\n",
      " [ 0.06232435 -0.02095403]]\n",
      "dETotal_dOh [0.03635031 0.04137032]\n",
      "dOuth_Dneth [[0.24130071 0.24061342]]\n",
      "deltaH [[0.00877135 0.00995425]]\n",
      "dWh [[0.00043857 0.00099543]]\n",
      "update [[0.14978072 0.24950229]\n",
      " [0.19978072 0.29950229]]\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Done - Partial\n",
    "dEo_dOh = deltaO * Wo\n",
    "dETotal_dOh = dEo_dOh.sum(axis=1)\n",
    "print (dEo_dOh)\n",
    "print('dETotal_dOh', dETotal_dOh)\n",
    "\n",
    "# Done\n",
    "dOuth_Dneth = activation_functions.sigmoid_derivative_chain(outH)\n",
    "print('dOuth_Dneth', dOuth_Dneth)\n",
    "\n",
    "\n",
    "# Done\n",
    "deltaH = dETotal_dOh * dOuth_Dneth \n",
    "print('deltaH', deltaH)\n",
    "\n",
    "# done\n",
    "# self.input\n",
    "dNeth_dw = X\n",
    "dWh = deltaH * dNeth_dw\n",
    "print('dWh', dWh)\n",
    "\n",
    "# Done\n",
    "updateH = Wh - lr * dWh\n",
    "print('update', updateH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the implemented Grad calculation for Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 error 0.2983711087600027\n",
      "1000 error 0.001114349453733746\n",
      "2000 error 0.00044486770391326887\n",
      "3000 error 0.00025152360241099405\n",
      "4000 error 0.00016427727363225536\n",
      "5000 error 0.00011622569943793622\n",
      "6000 error 8.653979465934606e-05\n",
      "7000 error 6.676957838285888e-05\n",
      "8000 error 5.288555201099971e-05\n",
      "9000 error 4.2742284255545085e-05\n",
      "[[0.01591419 0.98406371]]\n"
     ]
    }
   ],
   "source": [
    "reload(loss_functions)\n",
    "reload(activation_functions)\n",
    "reload(network)\n",
    "network.DEBUG = False\n",
    "\n",
    "X = np.array([[0.05, 0.10]], np.float64)\n",
    "\n",
    "Wh = np.array([[0.15, 0.2], [0.25, 0.3]], np.float64).T\n",
    "h = network.Layer(2, 2, 'sigmoid', weights=Wh, bias=0.35, label=\"H1\")\n",
    "\n",
    "Wo = np.array([[0.4, 0.45], [0.50, 0.55]], np.float64).T\n",
    "o = network.Layer(2, 2, 'sigmoid', weights=Wo, bias=0.6, label=\"H1\")\n",
    "Y = np.array([0.01, 0.99], np.float64)\n",
    "\n",
    "for i in range(10000):\n",
    "    netH, outH = h.feed_forward(X)\n",
    "    netO, outO = o.feed_forward(outH)\n",
    "\n",
    "    \n",
    "    Etotal = loss_functions.smd(outO, Y)\n",
    "    if (i % 1000) == 0:\n",
    "        print(i, 'error', Etotal)\n",
    "    \n",
    "    dEo_dw = loss_functions.smd_derivative_chain(outO, Y)\n",
    "    network.dprint(dEo_dw)\n",
    "    network.dprint (\"\")\n",
    "    network.dprint (\"==========================================\")\n",
    "    network.dprint (\"Back Propagate Layer O\")\n",
    "    network.dprint (\"==========================================\")\n",
    "    o.backpropagate(dETotal_dOut=dEo_dw)\n",
    "    network.dprint (\"==========================================\")\n",
    "    network.dprint (\"\")\n",
    "\n",
    "    network.dprint (\"==========================================\")\n",
    "    network.dprint (\"Back Propagate Layer H\")\n",
    "    network.dprint (\"==========================================\")\n",
    "    h.backpropagate(output_layer=o)\n",
    "    network.dprint (\"==========================================\")\n",
    "\n",
    "print (outO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the Fit Methods with the full network calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMD as the Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffled\n",
      "It: 1 Batch: 1 Epoch 0 Error: 0.29837111 lr: 0.500000 \n",
      "It: 2000 Batch: 1 Epoch 1999 Error: 0.00087915 lr: 0.500000 \n",
      "It: 4000 Batch: 1 Epoch 3999 Error: 0.00034362 lr: 0.500000 \n",
      "It: 6000 Batch: 1 Epoch 5999 Error: 0.00019080 lr: 0.500000 \n",
      "It: 8000 Batch: 1 Epoch 7999 Error: 0.00012257 lr: 0.500000 \n",
      "It: 10000 Batch: 1 Epoch 9999 Error: 0.00008538 lr: 0.500000 \n",
      "It: 12000 Batch: 1 Epoch 11999 Error: 0.00006263 lr: 0.500000 \n",
      "It: 14000 Batch: 1 Epoch 13999 Error: 0.00004763 lr: 0.500000 \n",
      "It: 16000 Batch: 1 Epoch 15999 Error: 0.00003719 lr: 0.500000 \n",
      "It: 18000 Batch: 1 Epoch 17999 Error: 0.00002965 lr: 0.500000 \n",
      "It: 20000 Batch: 1 Epoch 19999 Error: 0.00002402 lr: 0.500000 \n",
      "It: 22000 Batch: 1 Epoch 21999 Error: 0.00001971 lr: 0.500000 \n",
      "It: 24000 Batch: 1 Epoch 23999 Error: 0.00001636 lr: 0.500000 \n",
      "It: 26000 Batch: 1 Epoch 25999 Error: 0.00001370 lr: 0.500000 \n",
      "It: 28000 Batch: 1 Epoch 27999 Error: 0.00001156 lr: 0.500000 \n",
      "Finished \n",
      " It: 29778 Batch: 1 Epoch 29777 Train Loss: 0.00001000 lr: 0.500000 \n",
      "[[0.01314721 0.98682317]] 0.0031620172717675057\n"
     ]
    }
   ],
   "source": [
    "from utils import dataset_helper\n",
    "reload(loss_functions)\n",
    "reload(activation_functions)\n",
    "reload(network)\n",
    "reload(dataset_helper)\n",
    "network.DEBUG = False\n",
    "eps = 0.00001\n",
    "\n",
    "X = np.array([[0.05, 0.10]], np.float64)\n",
    "Y = np.array([[0.01, 0.99]], np.float64)\n",
    "\n",
    "Wh = np.array([[0.15, 0.2], [0.25, 0.3]], np.float64).T\n",
    "h = network.Layer(2, 2, 'sigmoid', weights=Wh, bias=0.35, label=\"H1\")\n",
    "\n",
    "Wo = np.array([[0.4, 0.45], [0.50, 0.55]], np.float64).T\n",
    "o = network.Layer(2, 2, 'sigmoid', weights=Wo, bias=0.6, label=\"Output\")\n",
    "\n",
    "model = network.NN(loss='smd')\n",
    "model.add_layer(h)\n",
    "model.add_layer(o)\n",
    "model.show_weights()\n",
    "\n",
    "model.fit(X, Y, max_iter=50000, \n",
    "          lr=0.5, epsilon=eps, \n",
    "          print_interval=2000)\n",
    "\n",
    "_, Y_ = model.feed_forward(X)\n",
    "\n",
    "mae = np.absolute(Y - Y_).mean()\n",
    "print(Y_, mae)\n",
    "assert(mae < 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Entropy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffled\n",
      "It: 1 Batch: 1 Epoch 0 Error: 1.65052853 lr: 0.100000 \n",
      "It: 2000 Batch: 1 Epoch 1999 Error: 0.23026661 lr: 0.100000 \n",
      "It: 4000 Batch: 1 Epoch 3999 Error: 0.17763656 lr: 0.100000 \n",
      "It: 6000 Batch: 1 Epoch 5999 Error: 0.15757797 lr: 0.100000 \n",
      "It: 8000 Batch: 1 Epoch 7999 Error: 0.14673802 lr: 0.100000 \n",
      "It: 10000 Batch: 1 Epoch 9999 Error: 0.13988631 lr: 0.100000 \n",
      "It: 12000 Batch: 1 Epoch 11999 Error: 0.13514499 lr: 0.100000 \n",
      "It: 14000 Batch: 1 Epoch 13999 Error: 0.13166350 lr: 0.100000 \n",
      "It: 16000 Batch: 1 Epoch 15999 Error: 0.12899745 lr: 0.100000 \n",
      "It: 18000 Batch: 1 Epoch 17999 Error: 0.12689090 lr: 0.100000 \n",
      "It: 20000 Batch: 1 Epoch 19999 Error: 0.12518550 lr: 0.100000 \n",
      "It: 22000 Batch: 1 Epoch 21999 Error: 0.12377782 lr: 0.100000 \n",
      "It: 24000 Batch: 1 Epoch 23999 Error: 0.12259734 lr: 0.100000 \n",
      "It: 26000 Batch: 1 Epoch 25999 Error: 0.12159422 lr: 0.100000 \n",
      "It: 28000 Batch: 1 Epoch 27999 Error: 0.12073225 lr: 0.100000 \n",
      "It: 30000 Batch: 1 Epoch 29999 Error: 0.11998444 lr: 0.100000 \n",
      "It: 32000 Batch: 1 Epoch 31999 Error: 0.11933028 lr: 0.100000 \n",
      "It: 34000 Batch: 1 Epoch 33999 Error: 0.11875385 lr: 0.100000 \n",
      "It: 36000 Batch: 1 Epoch 35999 Error: 0.11824266 lr: 0.100000 \n",
      "It: 38000 Batch: 1 Epoch 37999 Error: 0.11778674 lr: 0.100000 \n",
      "It: 40000 Batch: 1 Epoch 39999 Error: 0.11737803 lr: 0.100000 \n",
      "It: 42000 Batch: 1 Epoch 41999 Error: 0.11700995 lr: 0.100000 \n",
      "Finished \n",
      " It: 42058 Batch: 1 Epoch 42057 Train Loss: 0.11699983 lr: 0.100000 \n",
      "[[0.01864833 0.98116786]] 0.008740233820416547\n"
     ]
    }
   ],
   "source": [
    "from utils import dataset_helper\n",
    "reload(loss_functions)\n",
    "reload(activation_functions)\n",
    "reload(network)\n",
    "reload(dataset_helper)\n",
    "network.DEBUG = False\n",
    "eps = 0.117\n",
    "X = np.array([[0.05, 0.10]], np.float64)\n",
    "Y = np.array([[0.01, 0.99]], np.float64)\n",
    "\n",
    "Wh = np.array([[0.15, 0.2], [0.25, 0.3]], np.float64).T\n",
    "h = network.Layer(2, 3, 'sigmoid', weights=Wh, bias=0.35, label=\"H1\")\n",
    "\n",
    "Wo = np.array([[0.4, 0.45], [0.50, 0.55]], np.float64).T\n",
    "o = network.Layer(3, 2, 'sigmoid', weights=Wo, bias=0.6, label=\"Output\")\n",
    "\n",
    "model = network.NN(loss='cross_entropy')\n",
    "model.add_layer(h)\n",
    "model.add_layer(o)\n",
    "model.show_weights()\n",
    "\n",
    "model.fit(X, Y, max_iter=50000, \n",
    "          lr=0.1, epsilon=eps, \n",
    "          print_interval=2000)\n",
    "\n",
    "_, Y_ = model.feed_forward(X)\n",
    "\n",
    "mae = np.absolute(Y - Y_).mean()\n",
    "print(Y_, mae)\n",
    "assert(mae < 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffled\n",
      "It: 1 Batch: 1 Epoch 0 Error: 2.14189723 lr: 0.100000 \n",
      "It: 2000 Batch: 2 Epoch 666 Error: 0.81099390 lr: 0.100000 \n",
      "It: 4000 Batch: 1 Epoch 1333 Error: 0.81236228 lr: 0.100000 \n",
      "It: 6000 Batch: 3 Epoch 1999 Error: 0.79193816 lr: 0.100000 \n",
      "It: 8000 Batch: 2 Epoch 2666 Error: 0.79008874 lr: 0.100000 \n",
      "It: 10000 Batch: 1 Epoch 3333 Error: 0.77678096 lr: 0.100000 \n",
      "It: 12000 Batch: 3 Epoch 3999 Error: 1.51081722 lr: 0.100000 \n",
      "It: 14000 Batch: 2 Epoch 4666 Error: 0.59327045 lr: 0.100000 \n",
      "It: 16000 Batch: 1 Epoch 5333 Error: 0.75015765 lr: 0.100000 \n",
      "It: 18000 Batch: 3 Epoch 5999 Error: 0.33114743 lr: 0.100000 \n",
      "It: 20000 Batch: 2 Epoch 6666 Error: 0.25914678 lr: 0.100000 \n",
      "It: 22000 Batch: 1 Epoch 7333 Error: 0.21239291 lr: 0.100000 \n",
      "It: 24000 Batch: 3 Epoch 7999 Error: 0.17984687 lr: 0.100000 \n",
      "It: 26000 Batch: 2 Epoch 8666 Error: 0.23508779 lr: 0.100000 \n",
      "It: 28000 Batch: 1 Epoch 9333 Error: 0.14023271 lr: 0.100000 \n",
      "It: 30000 Batch: 3 Epoch 9999 Error: 0.12676762 lr: 0.100000 \n",
      "It: 32000 Batch: 2 Epoch 10666 Error: 0.11628129 lr: 0.100000 \n",
      "It: 34000 Batch: 1 Epoch 11333 Error: 0.10768334 lr: 0.100000 \n",
      "It: 36000 Batch: 3 Epoch 11999 Error: 0.10035658 lr: 0.100000 \n",
      "It: 38000 Batch: 2 Epoch 12666 Error: 0.13846206 lr: 0.100000 \n",
      "It: 40000 Batch: 1 Epoch 13333 Error: 0.08906569 lr: 0.100000 \n",
      "It: 42000 Batch: 3 Epoch 13999 Error: 0.08442527 lr: 0.100000 \n",
      "It: 44000 Batch: 2 Epoch 14666 Error: 0.11766293 lr: 0.100000 \n",
      "It: 46000 Batch: 1 Epoch 15333 Error: 0.07689614 lr: 0.100000 \n",
      "It: 48000 Batch: 3 Epoch 15999 Error: 0.07373047 lr: 0.100000 \n",
      "It: 50000 Batch: 2 Epoch 16666 Error: 0.07082555 lr: 0.100000 \n",
      "Finished \n",
      " It: 50000 Batch: 2 Epoch 16666 Train Loss: 0.07082555 lr: 0.100000 \n",
      "0.0\n",
      "[1 1 0] [1 1 0]\n"
     ]
    }
   ],
   "source": [
    "from utils import dataset_helper\n",
    "reload(loss_functions)\n",
    "reload(activation_functions)\n",
    "reload(network)\n",
    "reload(dataset_helper)\n",
    "network.DEBUG = False\n",
    "\n",
    "eps = np.finfo(np.float32).eps\n",
    "\n",
    "X = np.array([[0.05, 0.10], [0.05, 0.10], [0.10, 0.05]], np.float64)\n",
    "Y = np.array([[0.0, 1], [0.0, 1], [1., 0.]], np.float64)\n",
    "\n",
    "h1 = network.Layer(2, 10, 'sigmoid',  label=\"H1\")\n",
    "h2 = network.Layer(10, 10, 'sigmoid',   label=\"H2\")\n",
    "o = network.Layer(10, 2, 'sigmoid',  label=\"Output\")\n",
    "\n",
    "model = network.NN(loss='cross_entropy')\n",
    "model.add_layer(h1)\n",
    "model.add_layer(o)\n",
    "model.show_weights()\n",
    "\n",
    "model.fit(X, Y, max_iter=50000, \n",
    "          lr=0.1, epsilon=eps,\n",
    "          print_interval=2000)\n",
    "\n",
    "Y_ = np.array(model.predict(X))\n",
    "Y_ = Y_.argmax(axis=-1).flatten()\n",
    "Y = Y.argmax(axis=-1)\n",
    "mae = np.absolute(Y - Y_).mean()\n",
    "print(mae)\n",
    "print(Y, Y_)\n",
    "assert(mae < 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi class Classification Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def indices_to_one_hot(data, nb_classes):\n",
    "    \"\"\"Convert an iterable of indices to one-hot encoded labels.\"\"\"\n",
    "    targets = np.array(data).reshape(-1)\n",
    "    return np.eye(nb_classes)[targets]\n",
    "indices_to_one_hot(np.array([1,2,3,0]), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shuffled\n",
      "(100, 1, 4) (100, 4)\n",
      "It: 1 Batch: 1 Epoch 0 Train Loss: 14.97010230 lr: 0.100000 Val Loss: 1438.59433337\n",
      "(100, 1, 4) (100, 4)\n",
      "It: 2000 Batch: 400 Epoch 4 Train Loss: 2.70787524 lr: 0.100000 Val Loss: 227.24655795\n",
      "(100, 1, 4) (100, 4)\n",
      "It: 4000 Batch: 400 Epoch 9 Train Loss: 2.34233140 lr: 0.100000 Val Loss: 254.92569852\n",
      "(100, 1, 4) (100, 4)\n",
      "It: 6000 Batch: 400 Epoch 14 Train Loss: 1.78524444 lr: 0.100000 Val Loss: 306.80962227\n",
      "(100, 1, 4) (100, 4)\n",
      "It: 8000 Batch: 400 Epoch 19 Train Loss: 0.41490306 lr: 0.100000 Val Loss: 339.56480805\n",
      "(100, 1, 4) (100, 4)\n",
      "It: 10000 Batch: 400 Epoch 24 Train Loss: 2.37179206 lr: 0.100000 Val Loss: 364.75915871\n",
      "(100, 1, 4) (100, 4)\n",
      "It: 12000 Batch: 400 Epoch 29 Train Loss: 0.72841075 lr: 0.100000 Val Loss: 380.04061940\n",
      "(100, 1, 4) (100, 4)\n",
      "It: 14000 Batch: 400 Epoch 34 Train Loss: 0.23727880 lr: 0.100000 Val Loss: 406.44087707\n",
      "(100, 1, 4) (100, 4)\n",
      "It: 16000 Batch: 400 Epoch 39 Train Loss: 0.21009452 lr: 0.100000 Val Loss: 416.74367363\n",
      "(100, 1, 4) (100, 4)\n",
      "It: 18000 Batch: 400 Epoch 44 Train Loss: 0.25767608 lr: 0.100000 Val Loss: 438.57091021\n",
      "(100, 1, 4) (100, 4)\n",
      "It: 20000 Batch: 400 Epoch 49 Train Loss: 0.35344005 lr: 0.100000 Val Loss: 467.36195963\n",
      "(100, 1, 4) (100, 4)\n",
      "It: 22000 Batch: 400 Epoch 54 Train Loss: 0.30606398 lr: 0.100000 Val Loss: 460.91103789\n",
      "(100, 1, 4) (100, 4)\n",
      "It: 24000 Batch: 400 Epoch 59 Train Loss: 1.14842215 lr: 0.100000 Val Loss: 470.63722927\n",
      "(100, 1, 4) (100, 4)\n",
      "It: 26000 Batch: 400 Epoch 64 Train Loss: 0.36555204 lr: 0.100000 Val Loss: 490.78305282\n",
      "(100, 1, 4) (100, 4)\n",
      "It: 28000 Batch: 400 Epoch 69 Train Loss: 0.39285214 lr: 0.100000 Val Loss: 493.69020381\n",
      "(100, 1, 4) (100, 4)\n",
      "It: 30000 Batch: 400 Epoch 74 Train Loss: 0.04451375 lr: 0.100000 Val Loss: 511.11893970\n",
      "(100, 1, 4) (100, 4)\n",
      "It: 32000 Batch: 400 Epoch 79 Train Loss: 0.40515882 lr: 0.100000 Val Loss: 520.77192659\n",
      "(100, 1, 4) (100, 4)\n",
      "It: 34000 Batch: 400 Epoch 84 Train Loss: 4.00141482 lr: 0.100000 Val Loss: 528.20571003\n",
      "(100, 1, 4) (100, 4)\n",
      "It: 36000 Batch: 400 Epoch 89 Train Loss: 0.10268141 lr: 0.100000 Val Loss: 532.92712626\n",
      "(100, 1, 4) (100, 4)\n",
      "It: 38000 Batch: 400 Epoch 94 Train Loss: 0.08671597 lr: 0.100000 Val Loss: 550.56808599\n",
      "(100, 1, 4) (100, 4)\n",
      "It: 40000 Batch: 400 Epoch 99 Train Loss: 0.09589081 lr: 0.100000 Val Loss: 548.18513281\n",
      "(100, 1, 4) (100, 4)\n",
      "It: 42000 Batch: 400 Epoch 104 Train Loss: 0.12042175 lr: 0.100000 Val Loss: 569.59238381\n",
      "(100, 1, 4) (100, 4)\n",
      "It: 44000 Batch: 400 Epoch 109 Train Loss: 0.11302848 lr: 0.100000 Val Loss: 576.73799606\n",
      "(100, 1, 4) (100, 4)\n",
      "It: 46000 Batch: 400 Epoch 114 Train Loss: 0.14392935 lr: 0.100000 Val Loss: 583.79475238\n",
      "(100, 1, 4) (100, 4)\n",
      "It: 48000 Batch: 400 Epoch 119 Train Loss: 0.20657742 lr: 0.100000 Val Loss: 587.81046854\n",
      "(100, 1, 4) (100, 4)\n",
      "It: 50000 Batch: 400 Epoch 124 Train Loss: 0.08880901 lr: 0.100000 Val Loss: 594.32817478\n",
      "Finished \n",
      " It: 50000 Batch: 400 Epoch 124 Train Loss: 0.08880901 lr: 0.100000 Val Loss: 594.32817478\n",
      "Mae 0.04\n",
      "Time Spent  8.75787226600005\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import timeit\n",
    "from utils import dataset_helper\n",
    "reload(dataset_helper)\n",
    "reload(loss_functions)\n",
    "reload(activation_functions)\n",
    "reload(network)\n",
    "reload(dataset_helper)\n",
    "\n",
    "nclasses = 4\n",
    "nsamples = 500\n",
    "eps = np.finfo(np.float32).eps\n",
    "X,  X_val, Y, Y_val = dataset_helper.get_toy_data_multiclass(nclasses, nsamples)\n",
    "\n",
    "Y = dataset_helper.one_hot_encode(Y, nclasses)\n",
    "Y_val = dataset_helper.one_hot_encode(Y_val, nclasses)\n",
    "\n",
    "eps = 0.12\n",
    "lr = .1\n",
    "max_iter = 50000\n",
    "print_interval = 1000\n",
    "\n",
    "network.DEBUG = False\n",
    "\n",
    "eps = np.finfo(np.float32).eps\n",
    "\n",
    "h1 = network.Layer(10, 30, 'sigmoid', label=\"H1\")\n",
    "h2 = network.Layer(30, 10, 'sigmoid', label=\"H2\")\n",
    "o = network.Layer(10, nclasses, 'sigmoid', label=\"Output\")\n",
    "\n",
    "model = network.NN(loss='cross_entropy')\n",
    "model.add_layer(h1)\n",
    "model.add_layer(h2)\n",
    "model.add_layer(o)\n",
    "model.show_weights()\n",
    "\n",
    "\n",
    "print(\"\")\n",
    "start = time.process_time()\n",
    "model.fit(X, Y, max_iter=max_iter,           \n",
    "          lr=lr, epsilon=eps,\n",
    "          X_val=X_val, Y_val=Y_val,\n",
    "          print_interval=2000)\n",
    "\n",
    "Y_ = np.array(model.predict(X))\n",
    "Y_ = Y_.argmax(axis=-1).flatten()\n",
    "Y = Y.argmax(axis=-1)\n",
    "mae = np.absolute(Y - Y_).mean()\n",
    "print('Mae', mae)\n",
    "print(\"Time Spent \", time.process_time() - start)\n",
    "assert(mae < 0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'flatten'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-88bbf237bf95>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mY_val_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mY_val_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'flatten'"
     ]
    }
   ],
   "source": [
    "Y_val_ = np.array(model.predict(X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
