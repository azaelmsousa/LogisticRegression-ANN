{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append('../')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from NN import network, activation_functions, loss_functions\n",
    "from NN import ANN\n",
    "X = np.array([[1,2],[3,4]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Code running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layer  1\n",
      "[[0.38756401 0.31665851 0.42402114]\n",
      " [0.22774475 0.9877569  0.76386569]\n",
      " [0.93595815 0.27251824 0.86651682]] \n",
      "\n",
      "Output Layer \n",
      "[[0.21668265 0.06748016]\n",
      " [0.96205045 0.04683531]\n",
      " [0.40212244 0.00591343]\n",
      " [0.06774415 0.40054822]] \n",
      "\n",
      " Input size:  2\n",
      " Number of hidden layers:  1\n",
      " Number of perceptrons at each layer: \n",
      " HL 1: 3\n",
      " Number of classes: 2 \n",
      "\n",
      "Y\n",
      " [[1.51662691 0.49589861]\n",
      " [1.63569651 0.51950025]]\n",
      "\n",
      "a(Y)\n",
      " [[0.82004124 0.62149501]\n",
      " [0.83694851 0.6270309 ]]\n"
     ]
    }
   ],
   "source": [
    "# Random Init\n",
    "teste = ANN.ANN(\"sigmoid\")\n",
    "teste.initialize_random_weights(2, [3], 2)\n",
    "teste.show_weights()\n",
    "teste.show_setup()\n",
    "Y, aY = teste.foward_propagation(X)\n",
    "print(\"Y\\n\",Y)\n",
    "print(\"\\na(Y)\\n\",aY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing with the new Implementation by using the same weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Weights\n",
      "-------------------------------\n",
      "H1      (input=2, neurons=3, activation=sigmoid)\n",
      "[[0.38756401 0.31665851 0.42402114]\n",
      " [0.22774475 0.9877569  0.76386569]\n",
      " [0.93595815 0.27251824 0.86651682]]\n",
      "out     (input=3, neurons=2, activation=sigmoid)\n",
      "[[0.21668265 0.06748016]\n",
      " [0.96205045 0.04683531]\n",
      " [0.40212244 0.00591343]\n",
      " [0.06774415 0.40054822]]\n",
      "-------------------------------\n",
      "Forwardign H1 weights (2, 2) (3, 3)\n",
      "Forwardign out weights (2, 3) (4, 2)\n",
      "Y\n",
      " [[1.51662691 0.49589861]\n",
      " [1.63569651 0.51950025]]\n",
      "\n",
      "a(Y)\n",
      " [[0.82004124 0.62149501]\n",
      " [0.83694851 0.6270309 ]]\n"
     ]
    }
   ],
   "source": [
    "from importlib import reload\n",
    "reload(network)\n",
    "model = network.NN(loss='mse')\n",
    "model.add_layer(network.Layer(2, 3, 'sigmoid', weights=teste.hidden_layers[0], label=\"H1\"))\n",
    "model.add_layer(network.Layer(3, 2, 'sigmoid', weights=teste.output_layer, label=\"out\"))\n",
    "model.show_weights()\n",
    "\n",
    "Y, aY = model.feed_forward(X)\n",
    "\n",
    "print(\"Y\\n\",Y)\n",
    "print(\"\\na(Y)\\n\",aY)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Weights\n",
      "-------------------------------\n",
      "H1      (input=2, neurons=3, activation=sigmoid)\n",
      "[[0.06066682 0.96583963 0.5479115 ]\n",
      " [0.41136338 0.65547145 0.0899457 ]\n",
      " [0.91094766 0.32790101 0.47666563]]\n",
      "out     (input=3, neurons=2, activation=sigmoid)\n",
      "[[0.22150463 0.65530396]\n",
      " [0.6802047  0.39582851]\n",
      " [0.95746223 0.8118135 ]\n",
      " [0.50774691 0.14151367]]\n",
      "-------------------------------\n",
      "Forwardign H1 weights (2, 2) (3, 3)\n",
      "Forwardign out weights (2, 3) (4, 2)\n",
      "Y\n",
      " [[2.12959515 1.86871636]\n",
      " [2.31728139 1.98144741]]\n",
      "\n",
      "a(Y)\n",
      " [[0.89374657 0.86630968]\n",
      " [0.9102982  0.87883537]]\n"
     ]
    }
   ],
   "source": [
    "from importlib import reload\n",
    "reload(network)\n",
    "model = network.NN(loss='mse')\n",
    "model.add_layer(network.Layer(2, 3, 'sigmoid',  label=\"H1\"))\n",
    "model.add_layer(network.Layer(3, 2, 'sigmoid',  label=\"out\"))\n",
    "model.show_weights()\n",
    "\n",
    "Y, aY = model.feed_forward(X)\n",
    "\n",
    "print(\"Y\\n\",Y)\n",
    "print(\"\\na(Y)\\n\",aY)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax Sample and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forwardign output weights (2, 4) (5, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[ 5.1,  3.2, -1.7, -2. ],\n",
       "        [ 5.1,  3.2, -1.7, -2. ]]),\n",
       " array([[8.68426824e-01, 1.29889401e-01, 9.67232214e-04, 7.16543248e-04],\n",
       "        [8.68426824e-01, 1.29889401e-01, 9.67232214e-04, 7.16543248e-04]]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(activation_functions)\n",
    "reload(network)\n",
    "layer = network.Layer(4, 4, 'softmax', label=\"output\")\n",
    "val = np.array([[5.1, 3.2, -1.7, -2.0], [5.1, 3.2, -1.7, -2.0]])\n",
    "\n",
    "layer.feed_forward(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Summary\n",
      "-------------------------------\n",
      "H1      (input=2, neurons=3, activation=sigmoid)\n",
      "output  (input=3, neurons=2, activation=sigmoid)\n",
      "softmax (input=2, neurons=2, activation=softmax)\n",
      "-------------------------------\n",
      "Forwardign H1 weights (2, 2) (3, 3)\n",
      "Forwardign output weights (2, 3) (4, 2)\n",
      "Forwardign softmax weights (2, 2) (3, 2)\n",
      "Y\n",
      " [[0.86858984 0.95729205]\n",
      " [0.88366535 0.96444314]]\n",
      "\n",
      "a(Y)\n",
      " [[0.47783898 0.52216102]\n",
      " [0.47981653 0.52018347]]\n"
     ]
    }
   ],
   "source": [
    "from importlib import reload\n",
    "reload(network)\n",
    "model = network.NN(loss='cross_entropy')\n",
    "model.add_layer(network.Layer(2, 3, 'sigmoid',  label=\"H1\"))\n",
    "model.add_layer(network.Layer(3, 2, 'sigmoid',  label=\"output\"))\n",
    "model.add_layer(network.Layer(2, 2, 'softmax',  label=\"softmax\"))\n",
    "model.summary()\n",
    "\n",
    "Y, aY = model.feed_forward(X)\n",
    "\n",
    "print(\"Y\\n\",Y)\n",
    "print(\"\\na(Y)\\n\",aY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the loss functions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Squared Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [ 2.7  8.1 16.2]\n",
      "1 [ 2.59  7.77 15.54]\n",
      "2 [ 2.4855  7.4565 14.913 ]\n",
      "3 [ 2.386225  7.158675 14.31735 ]\n",
      "4 [ 2.29191375  6.87574125 13.7514825 ]\n",
      "5 [ 2.20231806  6.60695419 13.21390837]\n",
      "6 [ 2.11720216  6.35160648 12.70321296]\n",
      "7 [ 2.03634205  6.10902615 12.21805231]\n",
      "8 [ 1.95952495  5.87857485 11.75714969]\n",
      "9 [ 1.8865487   5.6596461  11.31929221]\n",
      "10 [ 1.81722127  5.4516638  10.9033276 ]\n",
      "11 [ 1.7513602   5.25408061 10.50816122]\n",
      "12 [ 1.68879219  5.06637658 10.13275316]\n",
      "13 [1.62935258 4.88805775 9.7761155 ]\n",
      "14 [1.57288495 4.71865486 9.43730972]\n",
      "15 [1.51924071 4.55772212 9.11544424]\n",
      "16 [1.46827867 4.40483601 8.80967203]\n",
      "17 [1.41986474 4.25959421 8.51918842]\n",
      "18 [1.3738715 4.1216145 8.243229 ]\n",
      "19 [1.33017793 3.99053378 7.98106755]\n",
      "20 [1.28866903 3.86600709 7.73201418]\n",
      "21 [1.24923558 3.74770673 7.49541347]\n",
      "22 [1.2117738  3.6353214  7.27064279]\n",
      "23 [1.17618511 3.52855533 7.05711065]\n",
      "24 [1.14237585 3.42712756 6.85425512]\n",
      "25 [1.11025706 3.33077118 6.66154237]\n",
      "26 [1.07974421 3.23923262 6.47846525]\n",
      "27 [1.050757   3.15227099 6.30454198]\n",
      "28 [1.02321915 3.06965744 6.13931489]\n",
      "29 [0.99705819 2.99117457 5.98234914]\n",
      "30 [0.97220528 2.91661584 5.83323168]\n",
      "31 [0.94859502 2.84578505 5.6915701 ]\n",
      "32 [0.92616527 2.7784958  5.55699159]\n",
      "33 [0.904857   2.71457101 5.42914202]\n",
      "34 [0.88461415 2.65384246 5.30768491]\n",
      "35 [0.86538344 2.59615033 5.19230067]\n",
      "36 [0.84711427 2.54134282 5.08268564]\n",
      "37 [0.82975856 2.48927568 4.97855135]\n",
      "38 [0.81327063 2.43981189 4.87962379]\n",
      "39 [0.7976071 2.3928213 4.7856426]\n",
      "40 [0.78272674 2.34818023 4.69636047]\n",
      "41 [0.76859041 2.30577122 4.61154244]\n",
      "42 [0.75516089 2.26548266 4.53096532]\n",
      "43 [0.74240284 2.22720853 4.45441706]\n",
      "44 [0.7302827 2.1908481 4.3816962]\n",
      "45 [0.71876857 2.1563057  4.31261139]\n",
      "46 [0.70783014 2.12349041 4.24698082]\n",
      "47 [0.69743863 2.09231589 4.18463178]\n",
      "48 [0.6875667  2.0627001  4.12540019]\n",
      "49 [0.67818836 2.03456509 4.06913018]\n"
     ]
    }
   ],
   "source": [
    "reload(loss_functions)\n",
    "I = np.array([[1.5], [4.5], [9]])\n",
    "Y_  = np.array([[0.5], [1.5], [3]])\n",
    "W = np.array([[1.8]])\n",
    "lr = 0.005\n",
    "eps  = 0.0001\n",
    "max_it = 50\n",
    "for i in range(max_it):\n",
    "    aY  = I * W\n",
    "    print(i, aY.flatten())\n",
    "    if np.absolute((Y_ - aY)).mean() < eps: \n",
    "        break\n",
    "    dC = loss_functions.mse_derivative(I, aY, Y_)\n",
    "    W = W - lr * dC\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Entropy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [ 2.7  8.1 16.2]\n",
      "1 [1.5615 4.6845 9.369 ]\n",
      "2 [1.01217375 3.03652125 6.0730425 ]\n",
      "3 [0.74712383 2.2413715  4.48274301]\n",
      "4 [0.61923725 1.85771175 3.7154235 ]\n",
      "5 [0.55753197 1.67259592 3.34519184]\n",
      "6 [0.52775918 1.58327753 3.16655506]\n",
      "7 [0.5133938  1.54018141 3.08036282]\n",
      "8 [0.50646251 1.51938753 3.03877506]\n",
      "9 [0.50311816 1.50935448 3.01870897]\n",
      "10 [0.50150451 1.50451354 3.00902708]\n",
      "11 [0.50072593 1.50217778 3.00435556]\n",
      "12 [0.50035026 1.50105078 3.00210156]\n",
      "13 [0.500169 1.500507 3.001014]\n",
      "14 [0.50008154 1.50024463 3.00048926]\n",
      "15 [0.50003934 1.50011803 3.00023607]\n",
      "16 [0.50001898 1.50005695 3.0001139 ]\n"
     ]
    }
   ],
   "source": [
    "reload(loss_functions)\n",
    "I = np.array([[1.5], [4.5], [9]])\n",
    "Y_  = np.array([[0.5], [1.5], [3]])\n",
    "W = np.array([[1.8]])\n",
    "\n",
    "for i in range(max_it):\n",
    "    aY  = I * W\n",
    "    print(i, aY.flatten())\n",
    "    if np.absolute((Y_ - aY)).mean() < eps: \n",
    "        break\n",
    "    dC = loss_functions.cross_entropy_derivative(I, aY, Y_)\n",
    "    W = W - lr * dC\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sum of Squared Errors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [ 2.7  8.1 16.2]\n",
      "1 [1.5615 4.6845 9.369 ]\n",
      "2 [1.01217375 3.03652125 6.0730425 ]\n",
      "3 [0.74712383 2.2413715  4.48274301]\n",
      "4 [0.61923725 1.85771175 3.7154235 ]\n",
      "5 [0.55753197 1.67259592 3.34519184]\n",
      "6 [0.52775918 1.58327753 3.16655506]\n",
      "7 [0.5133938  1.54018141 3.08036282]\n",
      "8 [0.50646251 1.51938753 3.03877506]\n",
      "9 [0.50311816 1.50935448 3.01870897]\n",
      "10 [0.50150451 1.50451354 3.00902708]\n",
      "11 [0.50072593 1.50217778 3.00435556]\n",
      "12 [0.50035026 1.50105078 3.00210156]\n",
      "13 [0.500169 1.500507 3.001014]\n",
      "14 [0.50008154 1.50024463 3.00048926]\n",
      "15 [0.50003934 1.50011803 3.00023607]\n",
      "16 [0.50001898 1.50005695 3.0001139 ]\n"
     ]
    }
   ],
   "source": [
    "reload(loss_functions)\n",
    "I = np.array([[1.5], [4.5], [9]])\n",
    "Y_  = np.array([[0.5], [1.5], [3]])\n",
    "W = np.array([[1.8]])\n",
    "\n",
    "for i in range(max_it):\n",
    "    aY  = I * W\n",
    "    print(i, aY.flatten())\n",
    "    if np.absolute((Y_ - aY)).mean() < eps: \n",
    "        break\n",
    "    dC = loss_functions.smd_derivative(I, aY, Y_)\n",
    "    W = W - lr * dC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
