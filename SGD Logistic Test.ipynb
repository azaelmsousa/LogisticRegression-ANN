{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from SGD import custom_SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X values \n",
      "[[1. 4. 7.]\n",
      " [1. 2. 6.]]\n",
      "Iter 0 theta: [ 0.79204728 -0.17385816 -1.12669268]\n",
      "RMSE error: 0.7068\n",
      "Iter 1 theta: [1.24104927 1.62377359 2.01713315]\n",
      "RMSE error: 0.7071\n",
      "Iter 2 theta: [ 0.7910493   0.72377365 -0.68286668]\n",
      "RMSE error: 0.5382\n",
      "Iter 3 theta: [1.06746351 1.9508098  1.31272243]\n",
      "RMSE error: 0.7071\n",
      "Iter 4 theta: [ 0.6174647  1.0508122 -1.3872704]\n",
      "RMSE error: 0.7018\n",
      "Iter 5 theta: [1.06245549 2.83407623 1.72931556]\n",
      "RMSE error: 0.7071\n",
      "Iter 6 theta: [ 0.61245551  1.93407626 -0.97068434]\n",
      "RMSE error: 0.1914\n",
      "Iter 7 theta: [ 0.5978657   2.06195888 -0.97969209]\n",
      "RMSE error: 0.1895\n",
      "Iter 8 theta: [ 0.54438596  2.06343483 -1.24635281]\n",
      "RMSE error: 0.3429\n",
      "Iter 9 theta: [0.7354739  2.87904569 0.11689236]\n",
      "RMSE error: 0.7066\n",
      "Iter 10 theta: [ 0.28581227  1.97972433 -2.58107647]\n",
      "RMSE error: 0.7071\n",
      "Iter 11 theta: [0.73578294 3.77961879 0.56872407]\n",
      "RMSE error: 0.7071\n",
      "Iter 12 theta: [ 0.28578664  2.8796262  -2.13125369]\n",
      "RMSE error: 0.6770\n",
      "Iter 13 theta: [0.71612522 4.602041   0.8816466 ]\n",
      "RMSE error: 0.7071\n",
      "Iter 14 theta: [ 0.26612533  3.70204123 -1.81835274]\n",
      "RMSE error: 0.0673\n",
      "Iter 15 theta: [ 0.28849362  3.82543646 -1.64481369]\n",
      "RMSE error: 0.0904\n",
      "Iter 16 theta: [ 0.23893906  3.741342   -1.93463371]\n",
      "RMSE error: 0.1137\n",
      "Iter 17 theta: [ 0.30166911  4.010362   -1.48647344]\n",
      "RMSE error: 0.2511\n",
      "Iter 18 theta: [ 0.14303242  3.6954564  -2.43710972]\n",
      "RMSE error: 0.6323\n",
      "Iter 19 theta: [0.54506982 5.30435643 0.37752732]\n",
      "RMSE error: 0.7071\n",
      "Iter 20 theta: [ 0.09507049  4.40435776 -2.32246866]\n",
      "RMSE error: 0.1339\n",
      "Iter 21 theta: [ 0.17728983  4.73907587 -1.7440129 ]\n",
      "RMSE error: 0.2179\n",
      "Iter 22 theta: [ 0.03904991  4.46347933 -2.57301079]\n",
      "RMSE error: 0.3744\n",
      "Iter 23 theta: [ 0.27662703  5.41517708 -0.90927633]\n",
      "RMSE error: 0.7046\n",
      "Iter 24 theta: [-0.17179764  4.51832791 -3.59982425]\n",
      "RMSE error: 0.7066\n",
      "Iter 25 theta: [ 0.27789641  6.31710677 -0.45196456]\n",
      "RMSE error: 0.7071\n",
      "Iter 26 theta: [-0.17208687  5.41714021 -3.15186424]\n",
      "RMSE error: 0.4511\n",
      "Iter 27 theta: [ 0.11488318  6.5652557  -1.14295627]\n",
      "RMSE error: 0.7059\n",
      "Iter 28 theta: [-0.3343611   5.66676715 -3.83842194]\n",
      "RMSE error: 0.6996\n",
      "Iter 29 theta: [ 0.11086622  7.44768181 -0.72182797]\n",
      "RMSE error: 0.7071\n",
      "Iter 30 theta: [-0.33912338  6.54770261 -3.42176558]\n",
      "RMSE error: 0.0921\n",
      "Iter 31 theta: [-0.28072943  6.7816566  -3.01281885]\n",
      "RMSE error: 0.0062\n",
      "Iter 32 theta: [-0.28300434  6.77994469 -3.02504937]\n",
      "RMSE error: 0.0059\n",
      "Iter 33 theta: [-0.28486001  6.7793523  -3.0346239 ]\n",
      "RMSE error: 0.0057\n",
      "Iter 34 theta: [-0.28640193  6.77961688 -3.0422012 ]\n",
      "RMSE error: 0.0056\n",
      "Iter 35 theta: [-0.2877071   6.78053833 -3.04826631]\n",
      "RMSE error: 0.0055\n",
      "Iter 36 theta: [-0.28883291  6.78196232 -3.05318338]\n",
      "RMSE error: 0.0054\n",
      "Iter 37 theta: [-0.2898226   6.78376946 -3.05722824]\n",
      "RMSE error: 0.0054\n",
      "Iter 38 theta: [-0.29070886  6.7858676  -3.06061051]\n",
      "RMSE error: 0.0053\n",
      "Iter 39 theta: [-0.2915165   6.78818582 -3.06348957]\n",
      "RMSE error: 0.0053\n",
      "Iter 40 theta: [-0.29226428  6.79066978 -3.06598652]\n",
      "RMSE error: 0.0053\n",
      "Iter 41 theta: [-0.29296645  6.79327795 -3.06819327]\n",
      "RMSE error: 0.0053\n",
      "Iter 42 theta: [-0.29363378  6.79597871 -3.07017952]\n",
      "RMSE error: 0.0053\n",
      "Iter 43 theta: [-0.29427441  6.79874801 -3.07199807]\n",
      "RMSE error: 0.0052\n",
      "Iter 44 theta: [-0.29489454  6.8015676  -3.07368888]\n",
      "RMSE error: 0.0052\n",
      "Iter 45 theta: [-0.29549881  6.80442366 -3.07528221]\n",
      "RMSE error: 0.0052\n",
      "Iter 46 theta: [-0.29609076  6.8073057  -3.07680095]\n",
      "RMSE error: 0.0052\n",
      "Iter 47 theta: [-0.29667307  6.8102058  -3.07826244]\n",
      "RMSE error: 0.0052\n",
      "Iter 48 theta: [-0.29724775  6.81311795 -3.07967979]\n",
      "RMSE error: 0.0052\n",
      "Iter 49 theta: [-0.29781635  6.81603763 -3.08106294]\n",
      "RMSE error: 0.0052\n",
      "Predicted: [0.99549877 0.00575383]\n",
      "Expected: [1. 0.]\n"
     ]
    }
   ],
   "source": [
    "custom_SGD.grad_logit_step_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X values \n",
      "[[1.799e+01 2.066e+01 1.178e+02 ... 1.974e-01 3.060e-01 8.503e-02]\n",
      " [2.029e+01 1.434e+01 1.351e+02 ... 1.625e-01 2.364e-01 7.678e-02]\n",
      " [9.000e+00 1.440e+01 5.636e+01 ... 1.389e-02 2.991e-01 7.804e-02]\n",
      " ...\n",
      " [1.720e+01 2.452e+01 1.142e+02 ... 1.899e-01 3.313e-01 1.339e-01]\n",
      " [1.403e+01 2.125e+01 8.979e+01 ... 7.963e-02 2.226e-01 7.617e-02]\n",
      " [1.303e+01 1.842e+01 8.261e+01 ... 5.013e-02 1.987e-01 6.169e-02]]\n",
      "\n",
      "Full batch\n",
      "Number of samples: 455\n",
      "Number of parameters: 31\n",
      "It: 1 Batch: 1 Epoch 0 Error: 0.31318681 lr: 0.01000000 \n",
      "It: 1000 Batch: 1 Epoch 999 Error: 0.05174280 lr: 0.01000000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/notebooks/local/LogisticRegression-ANN/SGD/custom_SGD.py:95: RuntimeWarning: overflow encountered in exp\n",
      "  h = 1 / (1 + np.exp(-dot))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It: 2000 Batch: 1 Epoch 1999 Error: 0.04284557 lr: 0.01000000 \n",
      "It: 3000 Batch: 1 Epoch 2999 Error: 0.04811405 lr: 0.01000000 \n",
      "It: 4000 Batch: 1 Epoch 3999 Error: 0.04395628 lr: 0.01000000 \n",
      "It: 5000 Batch: 1 Epoch 4999 Error: 0.04285718 lr: 0.01000000 \n",
      "It: 6000 Batch: 1 Epoch 5999 Error: 0.12857143 lr: 0.01000000 \n",
      "It: 7000 Batch: 1 Epoch 6999 Error: 0.04393103 lr: 0.01000000 \n",
      "It: 8000 Batch: 1 Epoch 7999 Error: 0.04938446 lr: 0.01000000 \n",
      "It: 9000 Batch: 1 Epoch 8999 Error: 0.03736264 lr: 0.01000000 \n",
      "It: 10000 Batch: 1 Epoch 9999 Error: 0.03516484 lr: 0.01000000 \n",
      "Finished \n",
      " It: 10000 Batch: 1 Epoch 9999 Train Loss: 0.03516484 lr: 0.01000000 \n",
      "finished  14.412104868999998\n",
      "Accuracy: 0.842\n",
      "Precision: 0.899\n",
      "Recall: 1.000\n",
      "\n",
      "Stochastic Mini batch\n",
      "Number of samples: 455\n",
      "Number of parameters: 31\n",
      "Shuffled\n",
      "It: 1 Batch: 1 Epoch 0 Error: 0.33000000 lr: 0.01000000 \n",
      "It: 1000 Batch: 5 Epoch 199 Error: 0.03636364 lr: 0.01000000 \n",
      "Finished \n",
      " It: 1470 Batch: 5 Epoch 293 Train Loss: 0.00000000 lr: 0.01000000 \n",
      "finished  0.6398439900000028\n",
      "Accuracy: 0.825\n",
      "Precision: 0.909\n",
      "Recall: 0.986\n",
      "\n",
      "Mini batch\n",
      "Number of samples: 455\n",
      "Number of parameters: 31\n",
      "It: 1 Batch: 1 Epoch 0 Error: 0.33000000 lr: 0.01000000 \n",
      "It: 1000 Batch: 5 Epoch 199 Error: 0.03641107 lr: 0.01000000 \n",
      "It: 2000 Batch: 5 Epoch 399 Error: 0.06349485 lr: 0.01000000 \n",
      "It: 3000 Batch: 5 Epoch 599 Error: 0.04545455 lr: 0.01000000 \n",
      "It: 4000 Batch: 5 Epoch 799 Error: 0.04545455 lr: 0.01000000 \n",
      "It: 5000 Batch: 5 Epoch 999 Error: 0.07272727 lr: 0.01000000 \n",
      "It: 6000 Batch: 5 Epoch 1199 Error: 0.04545455 lr: 0.01000000 \n",
      "It: 7000 Batch: 5 Epoch 1399 Error: 0.03636364 lr: 0.01000000 \n",
      "It: 8000 Batch: 5 Epoch 1599 Error: 0.04545150 lr: 0.01000000 \n",
      "It: 9000 Batch: 5 Epoch 1799 Error: 0.03636364 lr: 0.01000000 \n",
      "It: 10000 Batch: 5 Epoch 1999 Error: 0.03636364 lr: 0.01000000 \n",
      "Finished \n",
      " It: 10000 Batch: 5 Epoch 1999 Train Loss: 0.03636364 lr: 0.01000000 \n",
      "finished  0.5864132760000018\n",
      "Accuracy: 0.833\n",
      "Precision: 0.887\n",
      "Recall: 1.000\n",
      "\n",
      "Single Instance\n",
      "Number of samples: 455\n",
      "Number of parameters: 31\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unorderable types: int() > NoneType()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-7a3f141f2a9b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcustom_SGD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/notebooks/local/LogisticRegression-ANN/SGD/custom_SGD.py\u001b[0m in \u001b[0;36mSGD_test\u001b[0;34m()\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m     theta = SGD(lr, max_iter, X, y, batch_type='Single',\n\u001b[0;32m--> 348\u001b[0;31m                 epsilon=None, batch_sz=1, print_interval=print_interval)\n\u001b[0m\u001b[1;32m    349\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"finished \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/notebooks/local/LogisticRegression-ANN/SGD/custom_SGD.py\u001b[0m in \u001b[0;36mSGD\u001b[0;34m(lr, max_iter, X, y, lr_optimizer, epsilon, power_t, t, batch_type, batch_sz, print_interval, X_val, y_val)\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[0m__iteration_log\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[0merror_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m     \u001b[0;32mwhile\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepsilon\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlr_optimizer\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'invscaling'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m             \u001b[0meta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpower_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unorderable types: int() > NoneType()"
     ]
    }
   ],
   "source": [
    "custom_SGD.SGD_test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
